{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcribing mp3 file to numpy requires the FFmpeg. Follow the steps in this link to have it installed. [(How to install FFmpeg in windows)](https://www.wikihow.com/Install-FFmpeg-on-Windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers streamlit accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list | findstr requests\n",
    "!pip install requests==2.27.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list | findstr requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supported Languages:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "WhisperTokenizer has no attribute language_codes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Print supported languages\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupported Languages:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlanguage_codes\u001b[49m))  \u001b[38;5;66;03m# This is the correct attribute\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Print supported tasks\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSupported Tasks:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\wtengguangwa\\OneDrive - DXC Production\\Desktop\\pythonenv\\myenv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1104\u001b[0m, in \u001b[0;36mSpecialTokensMixin.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_tokens_to_ids(attr_as_tokens) \u001b[38;5;28;01mif\u001b[39;00m attr_as_tokens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m-> 1104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(key)\n",
      "\u001b[1;31mAttributeError\u001b[0m: WhisperTokenizer has no attribute language_codes"
     ]
    }
   ],
   "source": [
    "from transformers import WhisperProcessor\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
    "\n",
    "# Print supported languages\n",
    "print(\"Supported Languages:\")\n",
    "print(list(processor.tokenizer.language_codes))  # This is the correct attribute\n",
    "\n",
    "# Print supported tasks\n",
    "print(\"\\nSupported Tasks:\")\n",
    "print([\"transcribe\", \"translate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from transformers import  pipeline,AutoModelForSpeechSeq2Seq,AutoProcessor, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_id = \"openai/whisper-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "inputs = tokenizer(return_tensors=\"pt\", padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 2.0)--> Qu'est-ce que tu es, Mr Wayne?\n",
      "(2.0, 6.0)--> Je veux le vendre pour le espéril.\n",
      "(6.0, 8.0)--> Espéril?\n",
      "(8.0, 11.0)--> Oui, tu ne es pas en train de mourir.\n",
      "(11.0, 14.0)--> Tu as prévu de ne pas avoir trop de feu à ces espéril?\n"
     ]
    }
   ],
   "source": [
    "# Add these at the very beginning of your notebook, before any other imports\n",
    "import os\n",
    "os.environ['CURL_CA_BUNDLE'] = ''\n",
    "\n",
    "# os.environ[\"TRANSFORMERS_NO_SSL_VERIFY\"] = \"1\"\n",
    "\n",
    "# Now your regular imports\n",
    "import time\n",
    "from transformers import pipeline, AutoModelForSpeechSeq2Seq, AutoProcessor\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "pipe  = pipeline(\"automatic-speech-recognition\",\n",
    "                    \"openai/whisper-small\", \n",
    "                    chunk_length_s=30,\n",
    "                    stride_length_s=5,\n",
    "                    return_timestamps=True,\n",
    "                    device=device, \n",
    "                    generate_kwargs = {\"language\": 'French', \"task\": \"transcribe\"}) \n",
    "transcription = pipe(r\"./english_audio.mp3\" )\n",
    "\n",
    "\n",
    "\n",
    "formatted_lyrics = \"\"   \n",
    "for line in transcription['chunks']:\n",
    "    text = line[\"text\"]\n",
    "    ts = line[\"timestamp\"]\n",
    "    formatted_lyrics += f\"{ts}-->{text}\\n\"\n",
    "\n",
    "print(formatted_lyrics.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wtengguangwa\\OneDrive - DXC Production\\Desktop\\pythonenv\\myenv\\Lib\\site-packages\\urllib3\\connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 'huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Mandarin version\n",
    "pipe = pipeline(\"automatic-speech-recognition\",\n",
    "                \"openai/whisper-large-v3\", \n",
    "                chunk_length_s=30,\n",
    "                stride_length_s=5,\n",
    "                return_timestamps=True,\n",
    "                device=device,\n",
    "                generate_kwargs={\n",
    "                    \"language\": \"zh\",\n",
    "                    \"task\": \"translate\"\n",
    "                }) \n",
    "\n",
    "pipe.model.config.forced_decoder_ids = (\n",
    "  pipe.tokenizer.get_decoder_prompt_ids(\n",
    "    language=\"zh\", \n",
    "    task=\"translate\"\n",
    "  )\n",
    ")\n",
    "\n",
    "transcription = pipe(r\"C:\\Users\\wtengguangwa\\OneDrive - DXC Production\\Desktop\\astro_translator\\simpledemo/mini_sl_c4.mp3\" )\n",
    "\n",
    "\n",
    "\n",
    "formatted_lyrics = \"\"\n",
    "for line in transcription['chunks']:\n",
    "    text = line[\"text\"]\n",
    "    ts = line[\"timestamp\"]\n",
    "    formatted_lyrics += f\"{ts}-->{text}\\n\"\n",
    "\n",
    "print(formatted_lyrics.strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distil WISPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wtengguangwa\\OneDrive - DXC Production\\Desktop\\pythonenv\\myenv\\Lib\\site-packages\\urllib3\\connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 'huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\wtengguangwa\\OneDrive - DXC Production\\Desktop\\pythonenv\\myenv\\Lib\\site-packages\\urllib3\\connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 'huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\wtengguangwa\\OneDrive - DXC Production\\Desktop\\pythonenv\\myenv\\Lib\\site-packages\\urllib3\\connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 'huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\wtengguangwa\\OneDrive - DXC Production\\Desktop\\pythonenv\\myenv\\Lib\\site-packages\\urllib3\\connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 'huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\wtengguangwa\\OneDrive - DXC Production\\Desktop\\pythonenv\\myenv\\Lib\\site-packages\\urllib3\\connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 'huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\wtengguangwa\\OneDrive - DXC Production\\Desktop\\pythonenv\\myenv\\Lib\\site-packages\\urllib3\\connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 'huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\wtengguangwa\\OneDrive - DXC Production\\Desktop\\pythonenv\\myenv\\Lib\\site-packages\\urllib3\\connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 'huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\wtengguangwa\\OneDrive - DXC Production\\Desktop\\pythonenv\\myenv\\Lib\\site-packages\\urllib3\\connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 'huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\wtengguangwa\\OneDrive - DXC Production\\Desktop\\pythonenv\\myenv\\Lib\\site-packages\\urllib3\\connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 'huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\wtengguangwa\\OneDrive - DXC Production\\Desktop\\pythonenv\\myenv\\Lib\\site-packages\\urllib3\\connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 'huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    " model_id = \"distil-whisper/distil-small.en\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    return_timestamps=True,\n",
    "    chunk_length_s=15,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 6.96)--> deployed in a SDF as well as SAFA. So that's what they are using it for. But we do\n",
      "(6.96, 14.0)--> to vendor. The reason is because we are not a software company, we are not a systems integrated.\n",
      "(14.0, 14.8)--> All right?\n",
      "(14.8, 17.2)--> What we do is that we provide the energy, right?\n",
      "(17.2, 19.56)--> People like outside the SIs, right?\n",
      "(19.56, 20.96)--> They are the ones that build a car.\n",
      "(20.96, 24.0)--> So they'll take our engine, put in the the car and sell the car to the client.\n",
      "(24.0, 30.0)--> So our rule here is to provide the algorithm right the engine right for ASR.\n",
      "(30.0, 36.0)--> Now if I need to provide the engine for the text to speech or whatever, also we can do the same thing as well.\n",
      "(36.0, 41.0)--> Right? So that's why we deploy through ST. I hope you're familiar with STL.\n",
      "(41.0, 42.0)--> Right?\n",
      "(42.0, 45.12)--> Yeah, so we do through ST, they put it in the various key places.\n",
      "(45.12, 50.16)--> Now there are other applications I cannot share with you. But there are things like\n",
      "(52.08, 55.0)--> interview rooms, one-to-one interview rooms, one to one interview rooms, right?\n",
      "(55.0, 60.0)--> Where there's camera inside and then you, you know, you monitor the interview\n",
      "(60.0, 63.0)--> and then the microphone is embedded into the table, right?\n",
      "(63.0, 66.0)--> So these type of interviews, we also do, right?\n",
      "(66.0, 70.0)--> But unfortunately, I cannot share with you who is doing this like,\n",
      "(70.0, 74.0)--> but it's also doing through ST and then they deploy on the client's side.\n",
      "(74.0, 79.0)--> All right, so these are some of the things that we do and we do that these kind of use cases\n",
      "(80.0, 83.0)--> have the strongest chance of success.\n",
      "(83.0, 84.0)--> I understand.\n",
      "(84.0, 87.0)--> For the SDF, right, for SDF, right?\n",
      "(87.0, 94.28)--> I think this is your most important question that you want to take on the list of questions you asked me.\n",
      "(94.28, 97.84)--> The most important I think the reason is it was call center.\n",
      "(97.84, 100.12)--> Currently there are two lines inside call center.\n",
      "(100.12, 104.0)--> The newer call center is run by mostly all run by view IP.\n",
      "(104.0, 106.0)--> The voice over IP, right?\n",
      "(106.0, 110.0)--> The older concept will be PX, this type of the telephone lines.\n",
      "(110.0, 127.36)--> So if the newer ones are able to split the color and the operator signal already. So it's already a zero track, right, rather than a mono track. So we don't need to do all the fancy stuff like separating the audio to this speaker, that's quicker, right?\n",
      "(127.36, 129.76)--> So we don't need to do quicker separation, right?\n",
      "(129.76, 134.96)--> So that one, so easily, that problem, you know, you solve that part, right?\n",
      "(134.96, 137.4)--> You just need to figure out to do the ASR.\n",
      "(137.4, 142.28)--> So the ASR for operator is usually about 95% real world scenario.\n",
      "(142.28, 144.8)--> That's because the operator tend to speak very well, right?\n",
      "(144.8, 149.72)--> Now the remaining performance will depend on the caller and right now our caller\n",
      "(149.72, 155.0)--> accuracy is about 85 to 90 percent, right? Because a single amount we do it for very long already.\n",
      "(155.0, 159.0)--> So the over accuracy for the system is quite high.\n",
      "(159.0, 165.52)--> But only challenge of course the client side challenge is that every month they may have new products or new terms,\n",
      "(165.92, 171.44)--> right, for SEDF, new medical terms, and it may not be captured in the old dictionary line,\n",
      "(171.44, 175.68)--> right, and they need us to every half a year update the dictionary for them now\n",
      "(175.68, 178.64)--> So so we do that also we do a free\n",
      "(179.8, 185.4)--> yearly updates for the engine and then if there are new set of keywords, right?\n",
      "(185.4, 191.16)--> You know that their SOP, no, change every time so they are new keywords.\n",
      "(191.16, 193.6)--> So we're ejected into the engine and the engine can recognize\n",
      "(193.6, 199.68)--> right or they want us to the feedback to us that because our engine they do well\n",
      "(199.68, 203.96)--> for this particular road name right we'll take note of it and then we will boost the\n",
      "(203.96, 208.44)--> performance for those particular weaker wordsler, right? For example,\n",
      "(208.44, 216.32)--> Dari, back too late, right? Nobody uses it. So what happened is that we have to know improve the performance\n",
      "(216.32, 225.2)--> on those selected words like so customization renewal we do it for them so for a co-centered so in summary is that it's easy to do\n",
      "(225.2, 229.92)--> because the microphone is close to the mouth right it's easy to do because\n",
      "(229.92, 234.0)--> telephony is quite mature telephony a speech engine is quite mature. Telephoney is quite mature,\n",
      "(234.0, 236.0)--> is quite mature for us.\n",
      "(236.0, 238.0)--> And other at once that we are very familiar\n",
      "(238.0, 241.0)--> with the requirements of all call centers.\n",
      "(241.0, 245.6)--> Of course it's all real time now. and it runs on CPU, no GPU, because\n",
      "(245.6, 257.0)--> most of them are, you know, by the time they buy the new word GPU come out already. So most of their decoding is done on a server back end on site that is on CPU.\n",
      "(257.0, 262.0)--> All right? The real time latency is at 25 milliseconds, which is industrial standard, right?\n",
      "(262.0, 263.0)--> So... which is the industrial standard. Right.\n",
      "(263.0, 270.0)--> So, sorry, I think this is the the CPU server is the smaller board model, right, which is actually\n",
      "(270.0, 272.0)--> already quite good for deployment.\n",
      "(272.0, 277.0)--> Yeah, yeah, so we don't even need, we don't even need a very strong, our engine runs on laptop,\n",
      "(277.0, 285.44)--> right, so if we, if you have four gig of memory, right, You can run two, three copies of it easily. No problem.\n",
      "(285.44, 297.0)--> Okay. So, so, so, uh, so, uh, so how engine, right, is designed in a way, is for on-premise, right, secure on-premise deployment.\n",
      "(297.0, 303.2)--> If you have your own hosting solution, we are more than happy to go to a site.\n",
      "(303.2, 306.0)--> Put it there for a month and then you guys can use your shop.\n",
      "(306.0, 307.5)--> Right, it will be secure, safe.\n",
      "(307.5, 309.8)--> And if you don't need to touch your metal,\n",
      "(309.8, 312.0)--> it's even better if I can load you my laptop.\n",
      "(312.0, 316.0)--> Or you can find a laptop, an agate laptop, hardened OS, I can deploy there no problem.\n",
      "(316.0, 322.0)--> All right so this type of things I think we are very familiar with the call center very very familiar with\n",
      "(322.0, 323.76)--> including all the requirements\n",
      "(323.76, 330.56)--> and we have clear all the IM in and everything like right so other things like you use case\n",
      "(330.56, 334.8)--> that I think it's a low-hanging food It's like the one that I share to you with you.\n",
      "(334.8, 339.76)--> If you have a one-to-one interview. So the other things that I can review,\n",
      "(339.76, 345.84)--> for example, I work with SAF also through ST. Is that, uh, you're a Singaporean?\n",
      "(345.84, 347.32)--> Yeah, Singaporean.\n",
      "(347.32, 351.52)--> Okay, so when you do FF IRA or you have a tattoo, you're probably not 35 as well.\n",
      "(351.52, 354.0)--> So you do FF IRA or Reposse or Reposse, right?\n",
      "(354.0, 358.0)--> So the speech recognition now inside that we do is also us.\n",
      "(358.0, 364.08)--> So that particular use case is very easy to do because a 2% doctor patient talking\n",
      "(364.08, 368.6)--> right and then the microphone is somewhere on the table hidden runner all right\n",
      "(368.6, 377.0)--> it's recorded for austerity so that one easy to do because usually for report sick is only ask a few questions like, right?\n",
      "(377.0, 384.0)--> So, how are you, where you're very, very, very not feeling well, where it is type of, best at that question question and for the\n",
      "(384.0, 389.44)--> doctors right and then the patient will talk. So that but the challenge\n",
      "(389.44, 393.36)--> of the doctor for that is different from co-centered the challenge for that is different from co-centered.\n",
      "(393.36, 395.88)--> The challenge for that is because that one,\n",
      "(395.88, 397.56)--> the microphone is far away.\n",
      "(397.56, 400.32)--> So you need to invest in the microphone.\n",
      "(400.32, 405.6)--> We always say here is that never use a software to solve a hardware problem, right?\n",
      "(405.6, 408.56)--> So the problem is to acquire good speech signal.\n",
      "(408.56, 416.0)--> So don't, don't spend, don't spend countless donkey years, go and train an engine to do far fear right\n",
      "(416.0, 418.0)--> but again the engine not robust enough.\n",
      "(418.0, 421.0)--> So what you do is of course you get a better microphone.\n",
      "(421.0, 422.0)--> How much is microphone?\n",
      "(422.0, 425.36)--> 80 dollar, hundred dollar? It's nothing, right, to be honest.\n",
      "(426.56, 431.6)--> So we always recommend a good microphone to the SAF, things that they can use. They're secure,\n",
      "(431.6, 435.2)--> no Wi-Fi, no plug-in, everything. So they use those microphones,\n",
      "(435.2, 441.28)--> all right, and then they are able to, you know, perform maybe 85% out the box using my solution,\n",
      "(441.28, 445.04)--> right? And with a bit of fine tuning, a bit of customization I mentioned\n",
      "(445.04, 450.72)--> in the call sector use case, the accuracy went to the 95% but of course the speech to\n",
      "(450.72, 453.84)--> text accuracy is not important because ultimately they want the\n",
      "(453.84, 459.0)--> the the the the downstream application so for those applications like face to\n",
      "(459.0, 464.64)--> face the FFI report six side evaluation all these type of things.\n",
      "(464.64, 469.44)--> The downstream application is whether or not they can populate a formula basically.\n",
      "(469.44, 476.0)--> So that form was populated by an LLLA, a large language border, that accuracy was by 80% and they were happy, right?\n",
      "(476.0, 483.8)--> So overall, my system was 95% accurate for those face-to-face one-to-face control interviews now.\n",
      "(483.8, 486.0)--> We call it control interviews,\n",
      "(486.0, 488.56)--> but ultimately the bosses wanted to see\n",
      "(488.56, 490.56)--> is the whether or not the downstream tasks\n",
      "(490.56, 492.0)--> will perform very well.\n",
      "(492.0, 494.84)--> So we they, of course, all these have drawbacks now.\n",
      "(494.84, 497.12)--> Drawbacks is because sometimes, right,\n",
      "(497.12, 499.08)--> let's say for example, you can imagine, right,\n",
      "(499.08, 501.64)--> record sick, right, you'll fever, right?\n",
      "(501.64, 507.0)--> And then, when the doctor notes are well right is as the chick is reddish or something for example\n",
      "(507.0, 514.24)--> because the the order the he looks very puffy for example right these type of things will come up in speech on a right? So you lose that\n",
      "(514.24, 519.76)--> visual information right then, right? So for example, psychiatric evaluation,\n",
      "(519.76, 524.0)--> right? The doctor right now, this person, dressed not very well.\n",
      "(524.0, 526.0)--> He looks like he's suicidal, for example.\n",
      "(526.0, 529.0)--> And this will not be reflected in the speech map,\n",
      "(529.0, 531.0)--> unless it's explicitly spoken.\n",
      "(531.0, 534.6)--> So you will lose a bit of visual information so the form\n",
      "(534.6, 538.72)--> population the note-taking right will lose some information there so the\n",
      "(538.72, 547.0)--> expected loss is about 10% to 15% right then so therefore if you're if you have a speech to text and then you pump it into a note taking,\n",
      "(547.0, 553.04)--> right, you are expected to be 85% maximum because you lose some visual cues.\n",
      "(553.04, 555.68)--> So we perform quite well for these three things.\n",
      "(555.68, 561.08)--> And this year itself we are actually trolling already and fully going to deploying deployment\n",
      "(561.08, 563.0)--> for these three particular use cases.\n",
      "(563.0, 568.0)--> Yeah, in the, in the, I mean I don't share, I mean you can share the process.\n",
      "(568.0, 570.0)--> Right. In the, I mean that's like at least, right?\n",
      "(570.0, 576.0)--> So this type of, you can think of the universe of use case, is the 2% talking in a control environment.\n",
      "(576.0, 586.0)--> Right, that means it is it is it is it is it is it is it is it because my system doesn't need to overlap detection, right, is very easy to do.\n",
      "(586.0, 588.0)--> The accuracy is very high.\n",
      "(588.0, 593.84)--> So, so these two use cases are call center, because there's two lines, lines right I don't need to do\n",
      "(593.84, 600.04)--> separation right and the second the the interview right because it's\n",
      "(600.04, 604.0)--> control right I don't need to do separation as well. I don't need to do overlap detection.\n",
      "(604.0, 608.0)--> So what happens is that these two use cases we feel that is so easy to do, right?\n",
      "(608.0, 613.28)--> It's so easy to do, you have a very high chance of guaranteed success.\n",
      "(613.28, 615.28)--> And then at the same time of course,\n",
      "(615.28, 617.8)--> the pendulum strings, all the right,\n",
      "(617.8, 620.4)--> the other end, right, is also we are actually also doing,\n",
      "(620.4, 621.8)--> it's one of the toughest problems,\n",
      "(621.8, 624.56)--> we call it the holy grailer of the speech to Texas\n",
      "(624.56, 629.28)--> because everyone wants it. It's the meeting room solution. What do I mean? Is that you have\n",
      "(629.28, 638.0)--> let's say a meeting group, right? 8 to 12 to 16 depending on what are meeting like. could be a team meeting could be a board meeting right could be an AGM kind of thing.\n",
      "(638.0, 644.0)--> So that kind of use case is incredibly difficult to do.\n",
      "(644.0, 648.0)--> Simply because number one, the microphone is far away, right?\n",
      "(648.0, 652.0)--> You are not going to mark everyone, that's the, no one is going to do that.\n",
      "(652.0, 653.0)--> All right?\n",
      "(653.0, 656.0)--> So we work with American companies and local companies\n",
      "(656.0, 660.0)--> to develop maybe sound bars, who spend microphones,\n",
      "(660.0, 663.0)--> as well as hidden microphones, right?\n",
      "(666.0, 668.0)--> To do the meeting room kind of scenario. Then of course you inherit other problems,\n",
      "(668.0, 671.0)--> because I see eight people,\n",
      "(671.0, 676.48)--> you want to identify them 8 people into usually if you have 8 people and\n",
      "(676.96, 681.92)--> usually people put about two to three microphones so you take off the voice right as a water\n",
      "(681.92, 684.56)--> water right and then the microphone as the\n",
      "(684.56, 690.72)--> reservoir right you pour the water into one single corner the reservoir right\n",
      "(690.72, 694.92)--> then you ask me to can you tell me where where is water\n",
      "(694.92, 701.12)--> come from right so if I all the voice is stuck into one microphone one channel\n",
      "(701.12, 705.12)--> right now you are given the task right unlike the call center\n",
      "(705.12, 708.76)--> where you make it two channel one channel for caller one channel for operator\n",
      "(708.76, 713.88)--> right now in the meeting room right all the voice going to one channel right so let's say\n",
      "(713.88, 718.84)--> this channel had eight voices current current state of the art to do the\n",
      "(718.84, 725.0)--> separation right you call diorization to do the diorization of the voices right is at maybe\n",
      "(725.0, 730.28)--> October 65% all right so so if let's say you know like if you do AI for so\n",
      "(730.28, 734.88)--> long you know total total right is engineering principle right the more you do the more error you can\n",
      "(734.88, 739.6)--> is so awkward going to be this way right so that is a very difficult to do with the meeting room right\n",
      "(739.68, 743.44)--> separating the voices alone is already very difficult\n",
      "(743.44, 749.44)--> but let's say if you today you have a perfect well way of capturing each\n",
      "(749.44, 756.0)--> person's voice we do for a PMO the prime-in of this, right? I do with Cisco and another team, right?\n",
      "(756.0, 760.0)--> What they do is that every three per cent have a sound bar.\n",
      "(760.0, 766.72)--> A sound bar. So this sound bar only captured three voice right and the so every three seats right\n",
      "(766.72, 772.12)--> one minute one minute one minute one sound bar so that if that's 15 minutes\n",
      "(772.12, 774.0)--> five sound bars, right?\n",
      "(774.0, 778.0)--> So it's a very expensive solution right there, you can imagine, right?\n",
      "(778.0, 782.0)--> Right, so that one, of course, solved the diarization problem.\n",
      "(782.0, 785.0)--> That what problem will you face if you solve the\n",
      "(785.0, 786.0)--> the directization problem.\n",
      "(786.0, 787.0)--> If you solve the, the, the, the, the, the,\n",
      "(787.0, 790.0)--> meaning to say, you know, who spoke what, right?\n",
      "(790.0, 795.5)--> Every person spoke, that means you manage to filter out the voices, and every voice has been its own channel.\n",
      "(795.5, 800.5)--> So let's say there are 15 ministers there, you have 15 tracks, 15 stero tracks, right?\n",
      "(800.5, 805.0)--> Right, so, then the next problem is that some people will sit very far away from the microphone.\n",
      "(805.0, 807.0)--> Some people will see very close to the microphone.\n",
      "(807.0, 808.0)--> Right.\n",
      "(808.0, 811.0)--> So the buggars that sit far away from the microphone is distant voice.\n",
      "(811.0, 815.12)--> In other words, the signal will be weak, right? You cannot\n",
      "(815.12, 819.88)--> capture it easily. But luckily, luckily this also can be overcome if you can get\n",
      "(819.88, 824.04)--> very good soundbar. It's getting very good microphone because the microphone\n",
      "(824.04, 828.96)--> can do automatic gate adjustment adjustments right so it adjusts right they\n",
      "(828.96, 835.68)--> adjust they boost the person sitting away it boosts the microphone, and then it becomes better.\n",
      "(835.68, 840.08)--> Then of course now, so you see we always encourage where we work with people, right, we\n",
      "(840.08, 844.52)--> hope that when you produce the AI solution, it must be hardware software, especially\n",
      "(844.52, 847.0)--> for the super tough cases.\n",
      "(847.0, 850.6)--> So the super tough cases that meeting group with, we believe that everyone needs the\n",
      "(850.6, 853.48)--> meeting room solution, to be honest right everyone\n",
      "(853.48, 858.52)--> needs it okay that's why yeah so that's why that's the hardest one we feel\n",
      "(858.52, 864.72)--> right but if you can put hardware right then honestly between you and me way you don't need to use me\n",
      "(864.72, 868.72)--> you can use you can because most bought meetings all this right the English\n",
      "(868.72, 874.0)--> very good one don't need to use me but if you want to no do a, okay, maybe you can both together.\n",
      "(874.0, 875.0)--> All right?\n",
      "(875.0, 880.0)--> So these are the some of the use cases, the two easy ones I think, and the one hard one that I think\n",
      "(880.0, 883.84)--> you need to be more thorough.\n",
      "(885.84, 886.56)--> Okay\n",
      "(890.32, 891.36)--> We are so let's say that I have like\n",
      "(896.56, 909.0)--> For movie use case then you want to generate subtitles for those movies yeah have you guys tried something like these yes yes we work with a small company, companies that does this type of captioning, right?\n",
      "(909.0, 911.0)--> Yeah, we do that all the time.\n",
      "(911.0, 914.56)--> They use our software to get the first pass, right? But of course,\n",
      "(914.56, 918.96)--> captioning and subjectally, it depends on where your level of tech expertise is at.\n",
      "(918.96, 923.76)--> Right. So some enterprise, right, they are very hex savvy, right?\n",
      "(923.76, 927.76)--> Meaning to say, they already have their own internal software, right?\n",
      "(927.76, 932.48)--> They just pluck out their own instead of using Azua, they use hours, right?\n",
      "(932.48, 934.88)--> They just point the API to my my one finish\n",
      "(934.88, 938.88)--> so then they have their own song they have their own captioning software\n",
      "(938.88, 946.0)--> others so we do that we do for so far we only do for English Chinese Malaysia.\n",
      "(946.0, 951.36)--> Yeah, this one they share with me. We have a cat gone engine as well. We don't\n",
      "(951.36, 955.6)--> think it works very well but but they are quite happy. So, okay.\n",
      "(957.6, 969.0)--> Yeah, so we are only doing this tree for, so, and then it also depends on the, like I said, the company use case, like some of them are not tax heavy.\n",
      "(969.0, 973.36)--> They rely on third party software. Now I tell them like what I tell you,\n",
      "(973.36, 974.56)--> I'm not a software company.\n",
      "(974.56, 975.96)--> I can only give you an engine.\n",
      "(975.96, 978.4)--> So what at the end of the day is that you can give me\n",
      "(978.4, 981.32)--> the home, what you can do is I give you a very basic\n",
      "(981.32, 986.2)--> Linux software, right? Linux Linux software you put the movie inside, you\n",
      "(986.2, 990.84)--> know, you wait a few minutes, you get the transcription and then you see what you want\n",
      "(990.84, 994.0)--> to do with it. You get get the SRK file, basically.\n",
      "(994.0, 996.0)--> You get the SRK file and see how you want to do it.\n",
      "(996.0, 999.0)--> And then they edit directly on the SRK file, right?\n",
      "(999.0, 1002.0)--> So open the text and then text viewer or whatever.\n",
      "(1002.0, 1005.36)--> So those companies also exist. Okay.\n",
      "(1006.64, 1016.0)--> Let's say that I have like quite a least of maybe a forget what's that I only used in Malaysia like the places like San Diego.\n",
      "(1016.0, 1019.0)--> Yeah, those kind of things.\n",
      "(1019.0, 1029.72)--> I think I think those things can be customized for the yes, wanted to recognize right oh yeah so if I\n",
      "(1029.72, 1036.0)--> work with lessee MES compliance or whatever whatever. We put there, then there are a list of\n",
      "(1036.0, 1039.0)--> terms, right, insurance, terminal, banking,\n",
      "(1039.0, 1040.0)--> comes, I never see before,\n",
      "(1040.0, 1041.0)--> and right, a list of,\n",
      "(1041.0, 1046.0)--> so other places is a, names like all these things, yeah.\n",
      "(1046.0, 1050.0)--> So previously our customization time was very long, right?\n",
      "(1050.0, 1052.0)--> Because we need to retrain our engine.\n",
      "(1052.0, 1054.0)--> So it took about six months.\n",
      "(1054.0, 1055.0)--> That's very long ago.\n",
      "(1055.0, 1058.0)--> Then after that, we brought it down to six weeks.\n",
      "(1058.0, 1061.0)--> Right then now, we bring it down to six days.\n",
      "(1061.0, 1066.6)--> Yeah, we bring it down to, we brought it down to six days to customize and the\n",
      "(1066.6, 1081.48)--> difference is that we don't even need audio now, we just need the list of keywords. So that's what we do for all our clients really. Okay, so let's say that the engine\n",
      "(1081.48, 1089.0)--> is just provided as an API using, let's say, I just passed an MP3 file and then you'll return me the text.\n",
      "(1089.0, 1095.12)--> So currently, but however for those like on-prem deployment do you guys also\n",
      "(1095.12, 1100.88)--> provide the model weights etc or those model ways are close source like\n",
      "(1100.88, 1104.08)--> you guys will be close source like you guess will just be close source it will be close source\n",
      "(1104.08, 1109.04)--> those model weights will be close source yeah yeah that's it the model ways will be\n",
      "(1109.04, 1115.68)--> close but it will be it would just be a API yeah but how do you guys deploy on-prem if your if the model is up close?\n",
      "(1115.92, 1116.68)--> Yeah.\n",
      "(1116.68, 1117.68)--> Oh, yeah.\n",
      "(1117.68, 1119.68)--> Oh, no, okay.\n",
      "(1119.68, 1124.0)--> But the doctor is also accessible by...\n",
      "(1124.0, 1126.0)--> Not necessary.\n",
      "(1126.0, 1127.0)--> Not necessary.\n",
      "(1127.0, 1132.0)--> As in, you guys are able to encrypt the model weights within the doctor container.\n",
      "(1132.0, 1136.0)--> Yeah, but if you try really hard, of course you can definitely see the model weights.\n",
      "(1136.0, 1137.0)--> Oh, yeah.\n",
      "(1137.0, 1138.0)--> Yeah.\n",
      "(1138.0, 1139.0)--> Yeah.\n",
      "(1139.0, 1146.0)--> That's why I was thinking I was, no, to be frank, if you deploy on my doger container, I can, I can\n",
      "(1146.0, 1147.0)--> size it up, yeah, so.\n",
      "(1147.0, 1150.0)--> Yeah, yeah, yeah, yeah, but you know why we are okay with that?\n",
      "(1150.0, 1154.24)--> No, you're okay with that, because the model is updated every three months.\n",
      "(1154.24, 1155.6)--> Oh, okay, okay.\n",
      "(1155.6, 1158.64)--> So, so, yeah, a lot of people don't understand,\n",
      "(1158.64, 1161.12)--> now it's like, you know, last time the software cycle,\n",
      "(1161.12, 1164.48)--> the CITC cycle is five years right now every half a year\n",
      "(1164.48, 1170.8)--> some idiot will say that they have a best album right this because our\n",
      "(1170.8, 1173.0)--> industry is moving so fast. Right.\n",
      "(1173.0, 1175.0)--> And as you know, you and me, between you and me,\n",
      "(1175.0, 1177.0)--> there's no way you train one speech engine, right?\n",
      "(1177.0, 1179.0)--> And then last for five years one.\n",
      "(1179.0, 1181.0)--> Thus, speech engine, you train already, right?\n",
      "(1181.0, 1184.0)--> I tell you, only in think you can do a Sunday week,\n",
      "(1184.0, 1186.0)--> or a second a week, you learn eating out from me\n",
      "(1186.0, 1189.0)--> that, concho man, I guarantee you.\n",
      "(1189.0, 1190.0)--> All right?\n",
      "(1190.0, 1191.0)--> So that's what I do.\n",
      "(1191.0, 1192.0)--> I train your engine every day, right?\n",
      "(1192.0, 1192.92)--> So that I can keep up with the competition. I train your engine every day, right?\n",
      "(1192.92, 1195.0)--> So that I can keep up with the competition.\n",
      "(1195.0, 1196.0)--> Okay.\n",
      "(1196.0, 1197.0)--> Okay.\n",
      "(1197.0, 1200.0)--> So when we work with our clients, our deployment cycle used to be six months.\n",
      "(1200.0, 1202.0)--> Like every six months I put one new engine.\n",
      "(1202.0, 1203.88)--> Now it's three months already. We\n",
      "(1203.88, 1208.68)--> realize that the deployments like so well if you see my ways today you see my\n",
      "(1208.68, 1222.8)--> checkpoint so what it's just a checkpoint to be honest. I only have something better tuning the model to make it better.\n",
      "(1222.8, 1224.4)--> But that's our job, yeah.\n",
      "(1224.4, 1224.96)--> It's our job.\n",
      "(1224.96, 1225.96)--> Okay.\n",
      "(1225.96, 1226.96)--> Yeah.\n",
      "(1226.96, 1228.16)--> That's how we have our client safe cost.\n",
      "(1228.16, 1229.16)--> Right.\n",
      "(1229.16, 1230.16)--> You don't need to worry about this.\n",
      "(1230.16, 1232.16)--> You just need to worry about, you know,\n",
      "(1232.16, 1236.56)--> making sure the thing runs in your environment, your software or whatever.\n",
      "(1236.56, 1239.68)--> Like the integration of this model to the software.\n",
      "(1239.68, 1244.0)--> The integration is your pass-up. You take this model integrate your framework, your pass-up. you take this model integrate into your framework, your pass-up.\n",
      "(1244.0, 1248.72)--> What is between you and me? You tell me, I need a meeting room model, I need a movie\n",
      "(1248.72, 1253.0)--> captioning model, I need a telephony model, can you just give me one? Then, ah, okay.\n",
      "(1253.0, 1254.4)--> Hey, I've missed this list of keywords.\n",
      "(1254.4, 1255.4)--> I need to see.\n",
      "(1255.4, 1256.4)--> Can you help me?\n",
      "(1256.4, 1257.4)--> This is what I do.\n",
      "(1257.4, 1265.44)--> And I think the architecture is also quite long from last time or like do you do you also change our\n",
      "(1265.44, 1267.44)--> architecture?\n",
      "(1267.44, 1275.6)--> Oh yeah, your own architecture and we change our architecture every six months if the performance jumps.\n",
      "(1275.6, 1278.24)--> If the performance jumps, if the performance jumps, then we change every year.\n",
      "(1278.24, 1281.04)--> But now it is we realize we change every six months.\n",
      "(1281.04, 1285.92)--> Yeah, we've from, we've ordered, ited was what was that? It was a what was that? It was a squeeze former become\n",
      "(1285.92, 1291.92)--> seep former become yeah, I don't know what former now like or transformer based on it. Okay, okay\n",
      "(1298.4, 1307.4)--> last time I was last time when I was doing my master's team is reporting to me I cannot I just don't bother any more yeah last time I was last time when I was doing my masters I was working on a model with the\n",
      "(1307.8, 1309.2)--> Conformer architecture\n",
      "(1309.2, 1315.0)--> Yeah, and then I tried to benchmark against speechless because there was a playground.\n",
      "(1315.0, 1317.0)--> Yeah, yeah, yeah, yeah.\n",
      "(1317.0, 1320.0)--> Yeah, there was a speechless playground.\n",
      "(1320.0, 1322.0)--> Yeah, there was a speechless playground and I tried to benchmark against my own model.\n",
      "(1322.0, 1327.0)--> Yeah, but nowadays, some reason the playground was removed like.\n",
      "(1327.0, 1328.0)--> Yeah, it was.\n",
      "(1328.0, 1330.0)--> Yeah, I was, I didn't know, I didn't know, I'd tell you,\n",
      "(1330.0, 1332.0)--> I asked me yesterday like or something.\n",
      "(1332.0, 1343.0)--> Oh. I might have to check. They really played with my email. Okay, then hopefully I can get to revive it.\n",
      "(1343.0, 1344.0)--> Okay, okay.\n",
      "(1344.0, 1345.0)--> We did this year.\n",
      "(1345.0, 1348.0)--> Yeah, because, how to say, yeah, that one, oh,\n",
      "(1348.0, 1350.0)--> oh, yeah, that model was a long time ago.\n",
      "(1350.0, 1351.0)--> That was Coudi.\n",
      "(1351.0, 1354.0)--> Coundi wasn't even...\n",
      "(1354.0, 1355.0)--> County is...\n",
      "(1355.0, 1356.0)--> County wasn't even...\n",
      "(1356.0, 1357.0)--> Was HMM still.\n",
      "(1357.0, 1358.0)--> Yeah, not even...\n",
      "(1358.0, 1359.0)--> Not even during that...\n",
      "(1359.0, 1361.0)--> Oh.\n",
      "(1361.0, 1363.0)--> Yeah, that was a long time ago.\n",
      "(1363.0, 1366.0)--> Okay, that was was outdated, yeah.\n",
      "(1366.0, 1367.0)--> That was real outdated.\n",
      "(1367.0, 1368.0)--> That was a...\n",
      "(1368.0, 1370.0)--> Td and HMM, I think, if I'm not wrong.\n",
      "(1370.0, 1373.0)--> Yeah, this is a very old architecture.\n",
      "(1373.0, 1376.44)--> 2018, 2017.\n",
      "(1376.44, 1377.56)--> Yeah, HMM.\n",
      "(1377.56, 1378.56)--> Yeah.\n",
      "(1378.56, 1380.24)--> So right now we don't do that anymore.\n",
      "(1380.24, 1382.0)--> Yeah, we already move away from that.\n",
      "(1382.0, 1384.12)--> Okay. Yeah, but I remember the slice that I sent you right\n",
      "(1384.12, 1387.2)--> Oh, mono size is below 150 million if you read the\n",
      "(1389.4, 1394.08)--> the down my slice right, so we are always benchmarking against benchmarking against V3\n",
      "(1394.08, 1399.48)--> we spur V3 about 1.5 billion per meters we are always benchmarking a 10x\n",
      "(1399.48, 1413.6)--> model right because you see our staff run on GPU is optimized for ASEAN usage, so we have to see how a generic state-of-the-art model would look like compared to our like ours is highly optimistic yeah\n",
      "(1413.6, 1420.28)--> so in the meantime oh yeah and right now we do our own SDK so everything is\n",
      "(1420.28, 1426.2)--> in C plus plus so it is even smaller like our yeah that the standard\n",
      "(1426.2, 1438.2)--> here hugging phase models yeah so so in the mean down do you guys have like let's say an engine like a playground that to replace this?\n",
      "(1438.64, 1442.32)--> Yeah, that I can maybe share with my boss my supervisor.\n",
      "(1442.32, 1442.56)--> So we don't but what we can Maybe share with my boss, my supervisor.\n",
      "(1442.56, 1445.6)--> So we don't, but what we can do is,\n",
      "(1447.68, 1450.88)--> what we can do is, do you have some simulated audio\n",
      "(1450.88, 1456.72)--> that you can use to test simulated audio I am recording\n",
      "(1456.72, 1463.32)--> this these transcript also yeah maybe I could I could just put it inside yeah, a little on\n",
      "(1464.16, 1469.52)--> Good. I mean if you have any recording or audio where you can do is that we can\n",
      "(1469.72, 1472.44)--> We can open an APF for you if that's okay.\n",
      "(1473.0, 1476.0)--> Then we give you the we send you the instructions and then you try to use it for\n",
      "(1476.0, 1480.0)--> on week doing like then you see compare the results law.\n",
      "(1480.0, 1481.0)--> Okay.\n",
      "(1482.0, 1489.2)--> So you should you open the API yeah, that means that you send me the instructions\n",
      "(1489.76, 1496.72)--> on on how to use the API like a sample code oh okay okay okay then basically the\n",
      "(1496.72, 1507.0)--> the the API is a rest-food API or yeah rest- okay okay okay I think nothing else yeah for my side\n",
      "(1507.0, 1511.0)--> maybe maybe or Monday we will discuss more yeah we will study about this\n",
      "(1511.0, 1514.3)--> model yeah yeah're meeting more use\n",
      "(1514.3, 1519.44)--> kids for the cell. Otherwise we're having competing. I think the main\n",
      "(1519.8, 1522.28)--> no, our main priority now is the extra because\n",
      "(1532.0, 1534.0)--> extra Our main priority now is the estro because estro I won't say it's the low hanging fruit but it is most likely to secure a view. Okay.\n",
      "(1534.0, 1539.0)--> They have a formalacious, locus one,\n",
      "(1539.0, 1542.0)--> Mandarin, Baha'a Malay and English.\n",
      "(1542.0, 1547.12)--> I think they are English quite similar as ours but they are Mandarin a bit more\n",
      "(1547.64, 1551.24)--> a bit more advanced than his general Singaporeans love. Yeah\n",
      "(1551.92, 1555.0)--> Oh, which tested with Malaysian accent is fine.\n",
      "(1555.0, 1558.0)--> So, uh, so astro-kind of movies now.\n",
      "(1558.0, 1562.48)--> So maybe if I can see YouTube, I can download some clips and then we try our benchmark\n",
      "(1562.48, 1563.6)--> on my side also like can\n",
      "(1563.6, 1569.44)--> can that's what I mean then do also yeah so yeah yeah yeah I mean there are\n",
      "(1569.44, 1576.88)--> also other use case like we have we have the lower priority demos like a scam called detection kind of\n",
      "(1576.88, 1585.16)--> a model that basically yeah you know like basically nowadays every day once in your war, then you receive a caller asking you like\n",
      "(1585.6, 1592.36)--> telling you that they are from some Jinzab, Chongpoo, yeah, police headquarters and then they want you to provide them some information\n",
      "(1592.48, 1592.88)--> So if you want you to provide them some information.\n",
      "(1592.88, 1595.84)--> So you want to have a bought like an AI agent\n",
      "(1595.84, 1598.68)--> that filters away this kind of phone calls\n",
      "(1598.68, 1600.8)--> and prevent them from reaching out\n",
      "(1600.8, 1608.56)--> to the senior elderly or subscriber subscriber of our service. Yeah, so that is how\n",
      "(1608.56, 1615.6)--> that is the rationale of these these kind of things like yeah, but there is more lower priority right now because there isn't an immediate\n",
      "(1616.64, 1618.84)--> immediate client that who is interested.\n",
      "(1618.84, 1623.44)--> Yeah, so I think as true, as true is very important, yeah.\n",
      "(1623.44, 1627.2)--> As show, they have a lot of old recordings from last 20, 30 years.\n",
      "(1627.2, 1632.24)--> All the old recordings, they want to transcribe it and then they want to, right,\n",
      "(1632.24, 1635.92)--> Chong-pola, yeah, they want to play again once in a while. Yeah,\n",
      "(1635.92, 1637.92)--> With the subtitles, yeah.\n",
      "(1638.56, 1640.32)--> So I tell you because it's readily\n",
      "(1640.32, 1643.2)--> subtitally is auto audio captioning.\n",
      "(1643.2, 1645.72)--> So some challenges that I faced last time\n",
      "(1645.72, 1648.4)--> is the main challenges for this\n",
      "(1648.4, 1651.0)--> is that you have to figure out who spoke when.\n",
      "(1651.0, 1654.24)--> Right, there means that if the client wants, you know, to\n",
      "(1654.24, 1657.8)--> automatically label the person, right, I remember you are something the same\n",
      "(1657.8, 1665.76)--> problem as the meeting room where all the voices go into one, one, one reservoir, right, all the water go into one reservoir right all the water going to one reservoir right you see\n",
      "(1665.76, 1669.16)--> right yeah yeah you open the you open the audio check inside right is one\n",
      "(1669.16, 1676.28)--> track on it right so this is a big big problem for audio captioning and with my software last time they were able to cut the\n",
      "(1678.08, 1685.84)--> Transcribing time right nearly by 70% because the remaining time they realize that if your transcription is almost correct, right?\n",
      "(1686.0, 1689.5)--> The remaining time that you use is always to figure out who spoke when\n",
      "(1689.5, 1695.0)--> to label, who spoke that particular face. Yeah, that's the challenge for audio capture.\n",
      "(1695.0, 1700.0)--> So I think I think for the authorization if I'm not really interested in\n",
      "(1700.0, 1704.8)--> then the performance should be much more better at let's say that I don't\n",
      "(1704.8, 1709.68)--> really I don't really need that feature yeah but that's right but for\n",
      "(1709.68, 1712.48)--> captioning I think you would need though I don't know if you need that\n",
      "(1712.48, 1714.0)--> it was just something like that, right?\n",
      "(1714.0, 1718.0)--> But I don't know, because audio captioning is a different part,\n",
      "(1718.0, 1720.0)--> not, you have to shift the timing,\n",
      "(1720.0, 1722.0)--> a bit left, right, left, right, and then,\n",
      "(1722.0, 1724.0)--> because people read different timing\n",
      "(1724.0, 1728.0)--> then because when you produce the machine level timing\n",
      "(1728.0, 1732.0)--> the reading timing of a human being is different so what the yeah\n",
      "(1732.0, 1733.4)--> I actually remember what was the\n",
      "(1733.4, 1737.4)--> specification, but that's a different thing, right? So, but we'll figure out\n",
      "(1737.4, 1740.96)--> that when we'll cross that bridge when it comes up, right? So my main thing is\n",
      "(1740.96, 1743.44)--> hopefully the performance for the transcription is not bad first.\n",
      "(1744.24, 1745.6)--> Then you can easier talk to your boss.\n",
      "(1745.6, 1746.0)--> Right.\n",
      "(1746.0, 1747.64)--> Then yeah.\n",
      "(1747.64, 1748.64)--> Yeah.\n",
      "(1748.64, 1749.64)--> I mean.\n",
      "(1749.64, 1749.68)--> Okay.\n",
      "(1749.68, 1750.92)--> I'll inform my engineer first.\n",
      "(1751.16, 1751.96)--> Her name is Lee.\n",
      "(1759.0, 1761.0)--> She will she will cut you through the email on how to use the as your endpoint. Okay, okay. Thanks a lot.\n",
      "(1761.0, 1764.68)--> Remember this is on the cloud, it's not on the premise, right?\n",
      "(1764.68, 1772.28)--> So I think, let's say that Astro has a live TV broadcast, then in that case, in for those\n",
      "(1772.28, 1773.4)--> kind of scenario,\n",
      "(1773.4, 1776.68)--> then you guys will also have another kind of engine\n",
      "(1776.68, 1779.8)--> for life real-time deployment.\n",
      "(1779.8, 1784.0)--> Or can I also use this similar API for life?\n",
      "(1784.0, 1788.0)--> This API will be real, okay, this is offline,\n",
      "(1788.0, 1790.0)--> if it is an offline engine.\n",
      "(1790.0, 1792.0)--> We do have a different real-time one.\n",
      "(1792.0, 1795.0)--> For example, we do for MCI, the Parliament.\n",
      "(1795.0, 1797.0)--> Yeah, same thing one.\n",
      "(1797.0, 1799.0)--> Yeah, but it would be different,\n",
      "(1799.0, 1800.0)--> I guess Parliament, easy that we need to minister\n",
      "(1800.0, 1813.6)--> the English band, so yeah, different. Yeah, the life, I mean, I would do to like. but I think your works right Sure, okay.\n",
      "(1813.6, 1815.2)--> But I think your works, right?\n",
      "(1815.2, 1816.2)--> Yeah.\n",
      "(1816.2, 1818.8)--> Even, give it's the live TV.\n",
      "(1818.8, 1819.8)--> Yeah.\n",
      "(1821.2, 1822.4)--> Because it's just an API man.\n",
      "(1822.4, 1836.0)--> You, I mean, integration wise, I think I deploy on your side, then you'll be just your job to take the live stream and then you stream it to the API and then put a text tag on whatever part of the TV and you guys\n",
      "(1836.0, 1846.72)--> yeah I think I think the inference is very fast like 20 milliseconds so it's possible let's say I just do my own software engineering yeah yeah because\n",
      "(1846.72, 1859.0)--> because because let's say yeah yeah yeah because for live broadcasts, then it has to be very fast-life from what I believe.\n",
      "(1859.0, 1865.6)--> I mean, I haven't won it yet, but this is why I believe yeah yeah yeah correct correct so yeah\n",
      "(1865.6, 1872.0)--> it's real time real time is real time it means that when you when you pop then the thing\n",
      "(1872.0, 1876.24)--> was like the come out already yeah okay okay\n",
      "(1876.24, 1881.36)--> okay okay but let me know I'll send an email after lunch can again I'll\n",
      "(1881.36, 1883.0)--> allow you yeah thanks a lot I think so yeah yeah yeah yeah thanks thanks you soon Thank you again. I will follow up with you. Yeah.\n",
      "(1883.0, 1884.0)--> Thanks a lot, I think so.\n",
      "(1884.0, 1885.0)--> Yeah.\n",
      "(1885.0, 1886.0)--> Yeah.\n",
      "(1886.0, 1887.0)--> Yeah.\n",
      "(1887.0, 1892.0)--> So, uh, we'll meet again next Monday with the prof and my hiring manager.\n",
      "(1892.0, 1893.0)--> Yeah. And then we'll show. Sure, yeah.\n",
      "(1893.0, 1895.0)--> And then, you know, we're a portion, yeah.\n",
      "(1895.0, 1896.0)--> So I'll share.\n",
      "(1896.0, 1898.0)--> I'm not sure if Paul Chunka can make it, like,\n",
      "(1898.0, 1900.0)--> because I think he has lessons on the day,\n",
      "(1900.0, 1902.0)--> but it's okay, my side is only me only usually, yeah.\n",
      "(1902.0, 1903.5)--> Uh, okay.\n",
      "(1903.5, 1904.5)--> But, but...\n",
      "(1904.5, 1905.5)--> I'm, but...\n",
      "(1905.5, 1906.5)--> I'm supposed to come in.\n",
      "(1906.5, 1907.5)--> I'm supposed to come up, yeah.\n",
      "(1907.5, 1908.5)--> Okay, okay.\n",
      "(1908.5, 1909.5)--> But pricing wise, those kind of things,\n",
      "(1909.5, 1911.5)--> uh, proff may...\n",
      "(1911.5, 1915.0)--> needs to be here. No, no, I'm the guy.\n",
      "(1915.0, 1916.0)--> Oh, yeah, the guy, okay, Ken.\n",
      "(1916.0, 1917.0)--> Thanks a lot.\n",
      "(1917.0, 1918.0)--> I'm the senior scientist here.\n",
      "(1918.0, 1919.0)--> Okay.\n",
      "(1919.0, 1920.0)--> You can scientist here.\n",
      "(1920.0, 1921.0)--> So I take care of everything.\n",
      "(1921.0, 1922.0)--> Okay, Ken.\n",
      "(1922.0, 1924.6)--> Thanks a lot. Thanks a lot. Okay. okay. Thanks for audience. Oh okay, okay. Yeah, okay. See this one. All right. Bye.\n"
     ]
    }
   ],
   "source": [
    "transcription = pipe(r\"./speechlabmeeting1.mp3\" )\n",
    "\n",
    "\n",
    "\n",
    "formatted_lyrics = \"\"\n",
    "for line in transcription['chunks']:\n",
    "    text = line[\"text\"]\n",
    "    ts = line[\"timestamp\"]\n",
    "    formatted_lyrics += f\"{ts}-->{text}\\n\"\n",
    "\n",
    "print(formatted_lyrics.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
