{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"humarin/chatgpt_paraphraser_on_T5_base\")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"humarin/chatgpt_paraphraser_on_T5_base\").to(device)\n",
    "\n",
    "def paraphrase(\n",
    "    question,\n",
    "    num_beams=5,\n",
    "    num_beam_groups=5,\n",
    "    num_return_sequences=1,\n",
    "    repetition_penalty=10.0,\n",
    "    diversity_penalty=3.0,\n",
    "    no_repeat_ngram_size=2,\n",
    "    temperature=0.7,\n",
    "    max_length=128\n",
    "):\n",
    "    input_ids = tokenizer(\n",
    "        f'paraphrase: {question}',\n",
    "        return_tensors=\"pt\", padding=\"longest\",\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "    ).input_ids.to(device)\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        input_ids, temperature=temperature, repetition_penalty=repetition_penalty,\n",
    "        num_return_sequences=num_return_sequences, no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "        num_beams=num_beams, num_beam_groups=num_beam_groups,\n",
    "        max_length=max_length, diversity_penalty=diversity_penalty\n",
    "    )\n",
    "\n",
    "    res = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\miniconda3\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Israel is still grappling with the events of the 7 October attacks, which occurred one year ago. The military bases guarding the Gaza border were overwhelmed by Hamas militants, resulting in the deaths of at least 60 Israeli soldiers and others who were taken hostage.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph = \"\"\"\n",
    "One year on from the 7 October Hamas attacks, tough questions are still being asked within Israel about the deadliest day in its history, when the country's powerful army was caught off guard and swiftly overwhelmed.\n",
    "\n",
    "The BBC has heard accounts given to families of what happened at one military base that guarded the border with Gaza.\n",
    "\n",
    "The Nahal Oz base was overrun by Hamas gunmen on the morning of 7 October and more than 60 Israeli soldiers are reported to have been killed - with others taken hostage.\n",
    "\n",
    "Israel’s military is yet to publish its official inquiry into what happened there that day, but it has already briefed relatives of those killed there, and some have shared those details with the BBC.\n",
    "\"\"\"\n",
    "\n",
    "paraphrase(paragraph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Paragraph: \n",
      "One year on from the 7 October Hamas attacks, tough questions are still being asked within Israel about the deadliest day in its history, when the country's powerful army was caught off guard and swiftly overwhelmed.\n",
      "\n",
      "The BBC has heard accounts given to families of what happened at one military base that guarded the border with Gaza.\n",
      "\n",
      "The Nahal Oz base was overrun by Hamas gunmen on the morning of 7 October and more than 60 Israeli soldiers are reported to have been killed - with others taken hostage.\n",
      "\n",
      "Israel’s military is yet to publish its official inquiry into what happened there that day, but it has already briefed relatives of those killed there, and some have shared those details with the BBC.\n",
      "\n",
      "\n",
      "Paraphrased Paragraph: Israel is still grappling with the events that took place on 7 October, which are considered the deadliest day in its history, despite the fact that the country's powerful army was caught off guard and quickly overwhelmed, even after a year had passed. The BBC has been informed by families about the events that took place at a military base that guarded the Gaza border. The death toll of Hamas gunmen who overran the Nahal Oz base on the morning of October 7 has reached 60, with some soldiers being taken captive. The Israeli military has not yet released its formal investigation into the events of that day, but it has informed the families of those who lost their lives and some have shared these details with the BBC.\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the paragraph into sentences\n",
    "sentences = sent_tokenize(paragraph)\n",
    "\n",
    "paraphrased_sentences = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    paraphrased_result = paraphrase(sentence, num_beams=2, num_beam_groups=2, num_return_sequences=1)\n",
    "    paraphrased_sentences.append(paraphrased_result[0])  # Take the first paraphrased output\n",
    "\n",
    "# Join the paraphrased sentences back together\n",
    "paraphrased_paragraph = \" \".join(paraphrased_sentences)\n",
    "\n",
    "print(\"Original Paragraph:\", paragraph)\n",
    "print(\"\\nParaphrased Paragraph:\", paraphrased_paragraph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
