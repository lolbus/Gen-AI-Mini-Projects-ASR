{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install PyAudioWPatch\n",
    "\n",
    "from scipy.signal import resample\n",
    "import pyaudiowpatch as pyaudio\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "import torch\n",
    "import wave\n",
    "import soundcard as sc\n",
    "import soundfile as sf\n",
    "import scipy.io.wavfile as wavfile\n",
    "\n",
    "def save_wave(audio_frames,rate):\n",
    "    # Scale back to 16-bit PCM format for saving\n",
    "    audio_normalized = (audio_frames * 32767).astype(np.int16)\n",
    "    # Save the normalized audio to a WAV file\n",
    "    wav_file = f\"temp_audio.wav\"\n",
    "    wavfile.write(wav_file, rate, audio_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loopback device is {'index': 1, 'structVersion': 2, 'name': 'Headset (realme Buds Wireless 3', 'hostApi': 0, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0, 'isLoopbackDevice': False}\n",
      "Listening for audio... Speak now.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\miniconda3\\lib\\site-packages\\transformers\\models\\whisper\\modeling_whisper.py:694: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription (2.597s):  Special tokens have been added in the vocabulary make\n",
      "Transcription (0.524s):  screen.\n",
      "Stopped listening.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "INPUT_DEVICE = {1:'microphone', 2:'speaker'}\n",
    "\"\"\" for pc_speaker, go to the sound icon and right click-> choose sounds -> recordings -> choose streo Mix as default  \"\"\"\n",
    "INPUT_DEVICE_IDX = 1\n",
    "\n",
    "\n",
    "device='cuda'\n",
    "# Load model and processor\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\").to(device)\n",
    "# forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"french\", task=\"transcribe\")#for french to french\n",
    "# forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"french\", task=\"translate\")#for french to english\n",
    "forced_decoder_ids = None # for english to english\n",
    "\n",
    "\n",
    "\n",
    "# Initialize PyAudio\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "#  TODO create a nice function from this\n",
    "if INPUT_DEVICE[INPUT_DEVICE_IDX] == 'microphone':\n",
    "    micro_phone = p.get_default_input_device_info()\n",
    "\n",
    "elif INPUT_DEVICE[INPUT_DEVICE_IDX] == 'speaker':\n",
    "    # Get default WASAPI info\n",
    "    wasapi_info = p.get_host_api_info_by_type(pyaudio.paWASAPI)\n",
    "    # Get default WASAPI speakers\n",
    "    micro_phone = p.get_device_info_by_index(wasapi_info[\"defaultOutputDevice\"])\n",
    "    if not micro_phone[\"isLoopbackDevice\"]:\n",
    "        for loopback in p.get_loopback_device_info_generator():\n",
    "            \"\"\"\n",
    "            Try to find loopback device with same name(and [Loopback suffix]).\n",
    "            Unfortunately, this is the most adequate way at the moment.\n",
    "            \"\"\"\n",
    "            if micro_phone[\"name\"] in loopback[\"name\"]:\n",
    "                micro_phone = loopback\n",
    "                break\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print(f'The loopback device is {micro_phone}')\n",
    "\n",
    "# Settings for recording audio\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = int(micro_phone['defaultSampleRate'] ) \n",
    "WHISPER_RATE = 16000# Whisper expects 16kHz input\n",
    "CHUNK = 1024  # Number of frames per buffer\n",
    "TRANSCRIPTION_INTERVAL = 5  # Interval for transcription in seconds\n",
    "\n",
    "# Open a stream to record audio\n",
    "\n",
    "stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK, input_device_index=micro_phone[\"index\"])\n",
    "\n",
    "print(\"Listening for audio... Speak now.\")\n",
    "\n",
    "audio_buffer = np.array([], dtype=np.float32)  # Buffer to store accumulated audio\n",
    "last_transcription_time = time.time()  # Initialize the last transcription time\n",
    "audio_frames = np.array([], dtype=np.float32)  # Store raw audio frames\n",
    "\n",
    "# Open a text file to save the transcriptions\n",
    "transcription_file = open(\"transcriptions_cpu.txt\", \"a\")\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "\n",
    "        # Read a chunk of audio\n",
    "        data = stream.read(CHUNK, exception_on_overflow=False)  # Read a chunk of audio (1024 samples per chunk\n",
    "        audio_chunk = np.frombuffer(data, np.int16).flatten().astype(np.float32) / 32768.0\n",
    "        audio_chunk = resample(audio_chunk, int(len(audio_chunk) * WHISPER_RATE / RATE))  # Resample to 16kHz (it is needed as the WHISPER model is trained on 16KHZ data)\n",
    "\n",
    "\n",
    "        audio_buffer = np.append(audio_buffer, audio_chunk)\n",
    "        audio_frames = np.append(audio_frames, audio_chunk)  # Save raw audio data for MP3 conversion\n",
    "     \n",
    "        # Check if it's time to perform transcription\n",
    "        current_time = time.time()\n",
    "        if current_time - last_transcription_time >= TRANSCRIPTION_INTERVAL:\n",
    "            if audio_buffer.size > 0:  # Ensure there's audio to transcribe\n",
    "\n",
    "                start_translation_time = time.time()\n",
    "\n",
    "                input_features = processor(audio_buffer, sampling_rate=WHISPER_RATE, return_tensors=\"pt\").input_features\n",
    "                # Generate token ids\n",
    "                predicted_ids = model.generate(input_features.to(device), forced_decoder_ids=forced_decoder_ids)\n",
    "                # Decode token ids to text\n",
    "                transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
    "                transcription_text = transcription[0]\n",
    "\n",
    "                translation_duration = time.time() - start_translation_time\n",
    "\n",
    "                # Save the transcription with a timestamp to the file\n",
    "                timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                transcription_file.write(f\"[{timestamp}] {transcription_text}\\n\")\n",
    "                transcription_file.flush()  # Ensure it's written to the file immediately\n",
    "\n",
    "\n",
    "                # Print the transcription\n",
    "                print(f\"Transcription ({translation_duration:0.3f}s): {transcription_text}\")\n",
    "\n",
    "                # Clear buffer after transcription\n",
    "                audio_buffer = np.array([], dtype=np.float32)\n",
    "\n",
    "            last_transcription_time = current_time  # Update last transcription time\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Stopped listening.\")\n",
    "        save_wave(audio_frames, rate=WHISPER_RATE)\n",
    "        break\n",
    "\n",
    "# Stop and close the stream\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 26,\n",
       " 'structVersion': 2,\n",
       " 'name': 'Headphones (realme Buds Wireless 3 Stereo) [Loopback]',\n",
       " 'hostApi': 2,\n",
       " 'maxInputChannels': 2,\n",
       " 'maxOutputChannels': 0,\n",
       " 'defaultLowInputLatency': 0.003,\n",
       " 'defaultLowOutputLatency': 0.0,\n",
       " 'defaultHighInputLatency': 0.01,\n",
       " 'defaultHighOutputLatency': 0.0,\n",
       " 'defaultSampleRate': 44100.0,\n",
       " 'isLoopbackDevice': True}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyaudiowpatch as pyaudio\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "    # Get default WASAPI info\n",
    "wasapi_info = p.get_host_api_info_by_type(pyaudio.paWASAPI)\n",
    "# Get default WASAPI speakers\n",
    "default_speakers = p.get_device_info_by_index(wasapi_info[\"defaultOutputDevice\"])\n",
    "if not default_speakers[\"isLoopbackDevice\"]:\n",
    "    for loopback in p.get_loopback_device_info_generator():\n",
    "        \"\"\"\n",
    "        Try to find loopback device with same name(and [Loopback suffix]).\n",
    "        Unfortunately, this is the most adequate way at the moment.\n",
    "        \"\"\"\n",
    "        if default_speakers[\"name\"] in loopback[\"name\"]:\n",
    "            default_speakers = loopback\n",
    "            break\n",
    "\n",
    "default_speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 1,\n",
       " 'structVersion': 2,\n",
       " 'name': 'Headset (realme Buds Wireless 3',\n",
       " 'hostApi': 0,\n",
       " 'maxInputChannels': 2,\n",
       " 'maxOutputChannels': 0,\n",
       " 'defaultLowInputLatency': 0.09,\n",
       " 'defaultLowOutputLatency': 0.09,\n",
       " 'defaultHighInputLatency': 0.18,\n",
       " 'defaultHighOutputLatency': 0.18,\n",
       " 'defaultSampleRate': 44100.0,\n",
       " 'isLoopbackDevice': False}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.get_default_input_device_info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
