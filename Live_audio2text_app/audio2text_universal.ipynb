{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using Windows\n",
    "# pip install PyAudioWPatch soundcard soundfile\n",
    "\n",
    "# if using Linux\n",
    "# sudo apt install libasound-dev portaudio19-dev libportaudio2 libportaudiocpp0\n",
    "# sudo apt install ffmpeg libav-tools\n",
    "# sudo pip install pyaudio\n",
    "\n",
    "\n",
    "from scipy.signal import resample\n",
    "import pyaudio # import pyaudiowpatch as pyaudio (windows)\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "import torch\n",
    "import wave\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def save_wave(audio_frames, idx):\n",
    "    # Save the recorded audio to a WAV file\n",
    "    wav_file = f\"temp_audio_{idx}.wav\"\n",
    "    with wave.open(wav_file, 'wb') as wf:\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "        wf.setframerate(RATE)\n",
    "        wf.writeframes(b''.join(audio_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loopback device is {'index': 2, 'structVersion': 2, 'name': 'default', 'hostApi': 0, 'maxInputChannels': 32, 'maxOutputChannels': 32, 'defaultLowInputLatency': 0.008684807256235827, 'defaultLowOutputLatency': 0.008684807256235827, 'defaultHighInputLatency': 0.034807256235827665, 'defaultHighOutputLatency': 0.034807256235827665, 'defaultSampleRate': 44100.0}\n",
      "Listening for audio... Speak now.\n",
      "0.0017241538\n",
      "0.0015336275\n",
      "0.0016931891\n",
      "0.0017182529\n",
      "0.0017878115\n",
      "0.001507014\n",
      "0.0016484559\n",
      "0.0013958216\n",
      "0.0017108321\n",
      "0.0017400384\n",
      "0.0014868975\n",
      "0.0024459958\n",
      "0.0016168058\n",
      "0.0012611449\n",
      "0.00206092\n",
      "0.0017777979\n",
      "0.002091229\n",
      "0.0024159849\n",
      "0.0015548766\n",
      "0.0021038651\n",
      "0.0016075373\n",
      "0.0021899045\n",
      "0.0016685128\n",
      "0.0014237761\n",
      "0.0013531446\n",
      "0.0017706156\n",
      "0.0013680756\n",
      "0.0017315149\n",
      "0.0018932223\n",
      "0.0020320117\n",
      "0.0014073849\n",
      "0.0015192032\n",
      "0.0014170408\n",
      "0.0022553802\n",
      "0.0020716786\n",
      "0.0018748939\n",
      "0.0047809184\n",
      "0.0031222403\n",
      "0.0023206472\n",
      "0.0020730197\n",
      "0.0019168854\n",
      "0.0018161535\n",
      "0.002676338\n",
      "0.0021605492\n",
      "0.0019904375\n",
      "0.0019566715\n",
      "0.0019472837\n",
      "0.0018425584\n",
      "0.0025268495\n",
      "0.002670586\n",
      "0.0019905567\n",
      "0.0018015802\n",
      "0.0019029379\n",
      "0.0033954084\n",
      "0.003537178\n",
      "0.001985401\n",
      "0.0032013655\n",
      "0.0025615692\n",
      "0.0019711852\n",
      "0.0019462407\n",
      "0.0016041398\n",
      "0.0017613769\n",
      "0.0018453598\n",
      "0.0014841259\n",
      "0.0015645027\n",
      "0.0015302002\n",
      "0.0016261637\n",
      "0.001673758\n",
      "0.0012747347\n",
      "0.0018225908\n",
      "0.0017205179\n",
      "0.0013869107\n",
      "0.0016408861\n",
      "0.0018213689\n",
      "0.0013909042\n",
      "0.0016275048\n",
      "0.0014152527\n",
      "0.0013501644\n",
      "0.0015723109\n",
      "0.0014317632\n",
      "0.0014884472\n",
      "0.0015079081\n",
      "0.0013099313\n",
      "0.0013204515\n",
      "0.0028164089\n",
      "0.008027762\n",
      "0.055104017\n",
      "0.12905252\n",
      "0.15543589\n",
      "0.14182332\n",
      "0.13020316\n",
      "0.1391811\n",
      "0.13670865\n",
      "0.16327924\n",
      "0.20071515\n",
      "0.16018298\n",
      "0.17811432\n",
      "0.12515324\n",
      "0.14491516\n",
      "0.17497525\n",
      "0.1605739\n",
      "0.16752061\n",
      "0.14922866\n",
      "0.11528179\n",
      "0.07483417\n",
      "0.08748552\n",
      "0.10513863\n",
      "0.117301494\n",
      "0.109043896\n",
      "0.08376357\n",
      "0.062018067\n",
      "0.042878717\n",
      "0.036011785\n",
      "0.018559039\n",
      "0.013543308\n",
      "0.007601589\n",
      "0.009913236\n",
      "0.007620007\n",
      "0.0070945323\n",
      "0.040614605\n",
      "0.028650254\n",
      "0.037434757\n",
      "0.04543391\n",
      "0.04843375\n",
      "0.04034117\n",
      "0.038529873\n",
      "0.027271599\n",
      "0.019643962\n",
      "0.011821777\n",
      "0.017018586\n",
      "0.022357225\n",
      "0.05622679\n",
      "0.037238985\n",
      "0.046182185\n",
      "0.035106957\n",
      "0.04904461\n",
      "0.02191341\n",
      "0.06443998\n",
      "0.062481403\n",
      "0.04602015\n",
      "0.087055385\n",
      "0.042278796\n",
      "0.03693995\n",
      "0.01553458\n",
      "0.02182889\n",
      "0.016723901\n",
      "0.025934607\n",
      "0.07106012\n",
      "0.083499044\n",
      "0.11140099\n",
      "0.10788855\n",
      "0.10649705\n",
      "0.08632743\n",
      "0.05017087\n",
      "0.04086995\n",
      "0.04804176\n",
      "0.0322856\n",
      "0.022473782\n",
      "0.018749386\n",
      "0.028926253\n",
      "0.027282774\n",
      "0.07550019\n",
      "0.056580186\n",
      "0.056020975\n",
      "0.040258914\n",
      "0.04276079\n",
      "0.028977364\n",
      "0.03819886\n",
      "0.035223603\n",
      "0.032057762\n",
      "0.032592565\n",
      "0.02760142\n",
      "0.029715538\n",
      "0.021786064\n",
      "0.019981712\n",
      "0.011846721\n",
      "0.0099315345\n",
      "0.009227395\n",
      "0.007820398\n",
      "0.0034399927\n",
      "0.0044510365\n",
      "0.0020726323\n",
      "0.0032396019\n",
      "0.0022569597\n",
      "0.010845304\n",
      "0.015375078\n",
      "0.047591537\n",
      "0.023872167\n",
      "0.025301725\n",
      "0.10755706\n",
      "0.11328867\n",
      "0.10157749\n",
      "0.08677682\n",
      "0.05361104\n",
      "0.029087901\n",
      "0.049060374\n",
      "0.06636587\n",
      "0.072111964\n",
      "0.072424024\n",
      "0.06924069\n",
      "0.059246212\n",
      "0.048806608\n",
      "0.059848666\n",
      "0.078531206\n",
      "0.08003312\n",
      "0.09491059\n",
      "0.11709422\n",
      "0.12384164\n",
      "0.10792899\n",
      "0.08412838\n",
      "0.12354949\n",
      "0.116464496\n",
      "0.09991467\n",
      "0.06786591\n",
      "0.046241283\n",
      "0.0914858\n",
      "0.096808076\n",
      "0.09151459\n",
      "0.05382824\n",
      "0.034567207\n",
      "0.02972737\n",
      "0.02718988\n",
      "0.060088426\n",
      "0.04489535\n",
      "0.02466625\n",
      "0.01882422\n",
      "0.037158757\n",
      "0.04243204\n",
      "0.035536617\n",
      "0.046096265\n",
      "0.050851583\n",
      "0.050216436\n",
      "0.04894063\n",
      "0.034090817\n",
      "0.018971235\n",
      "0.013049692\n",
      "0.012610704\n",
      "0.009952635\n",
      "0.008122414\n",
      "0.005733818\n",
      "0.0063218772\n",
      "0.0067396164\n",
      "0.006323546\n",
      "0.0066118836\n",
      "0.007180184\n",
      "0.0076991916\n",
      "0.007393837\n",
      "0.032329798\n",
      "0.039621413\n",
      "0.026240975\n",
      "0.040913373\n",
      "0.060991287\n",
      "0.054789424\n",
      "0.0365206\n",
      "0.020655304\n",
      "0.017905533\n",
      "0.016171336\n",
      "0.015159816\n",
      "0.04389277\n",
      "0.03596148\n",
      "0.036583543\n",
      "0.016542852\n",
      "0.011994362\n",
      "0.01583895\n",
      "0.054957926\n",
      "0.061273247\n",
      "0.034166455\n",
      "0.029834956\n",
      "0.036070406\n",
      "0.043527365\n",
      "0.03913951\n",
      "0.03485006\n",
      "0.04667741\n",
      "0.03977111\n",
      "0.044380933\n",
      "0.040576905\n",
      "0.029928267\n",
      "0.02632606\n",
      "0.016677678\n",
      "0.01420477\n",
      "0.011810809\n",
      "0.008920521\n",
      "0.0068615377\n",
      "0.007350117\n",
      "0.0056363344\n",
      "0.0042973757\n",
      "0.004129976\n",
      "0.014039457\n",
      "0.011742473\n",
      "0.015320212\n",
      "0.016644776\n",
      "0.012553722\n",
      "0.009314746\n",
      "0.008329302\n",
      "0.0062230825\n",
      "0.030346543\n",
      "0.042820454\n",
      "0.051699936\n",
      "0.03967619\n",
      "0.033834666\n",
      "0.041759253\n",
      "0.052998126\n",
      "0.041307718\n",
      "0.032097787\n",
      "0.022519588\n",
      "0.045648605\n",
      "0.06584814\n",
      "0.08619669\n",
      "0.08812168\n",
      "0.096272826\n",
      "0.05782041\n",
      "0.02613315\n",
      "0.021019667\n",
      "0.023564398\n",
      "0.041657478\n",
      "0.046017945\n",
      "0.044869304\n",
      "0.037479073\n",
      "0.03725046\n",
      "0.028502882\n",
      "0.020520508\n",
      "0.021111429\n",
      "0.019093722\n",
      "0.020621628\n",
      "0.015046328\n",
      "0.011764437\n",
      "0.0069102347\n",
      "0.0072569847\n",
      "0.0055934787\n",
      "0.019727707\n",
      "0.040733516\n",
      "0.035693645\n",
      "0.02858591\n",
      "0.016018838\n",
      "0.011389375\n",
      "0.0141123235\n",
      "0.017822266\n",
      "0.014097929\n",
      "0.006482154\n",
      "0.0038540363\n",
      "0.0060723126\n",
      "0.016294718\n",
      "0.031137347\n",
      "0.029961646\n",
      "0.021936983\n",
      "0.022677392\n",
      "0.023745716\n",
      "0.016242594\n",
      "0.009632856\n",
      "0.008277029\n",
      "0.017996848\n",
      "0.053367496\n",
      "0.059612393\n",
      "0.075375915\n",
      "0.077264786\n",
      "0.047940284\n",
      "0.026379794\n",
      "0.021463722\n",
      "0.027215362\n",
      "0.03842649\n",
      "0.028808117\n",
      "0.021090657\n",
      "0.019647121\n",
      "0.020128727\n",
      "0.0219585\n",
      "0.024698347\n",
      "0.029848576\n",
      "0.024316937\n",
      "0.011313319\n",
      "0.01185292\n",
      "0.008592099\n",
      "0.007836163\n",
      "0.006329477\n",
      "0.0050267577\n",
      "0.0039301813\n",
      "0.004217148\n",
      "0.002826184\n",
      "0.0026932955\n",
      "0.0028562248\n",
      "0.0026982129\n",
      "0.0023598373\n",
      "0.0022285879\n",
      "0.0020208657\n",
      "0.0021491945\n",
      "0.0020095408\n",
      "0.0025826097\n",
      "0.0023805797\n",
      "0.0019815862\n",
      "0.0047652125\n",
      "0.030305177\n",
      "0.07305333\n",
      "0.066447884\n",
      "0.10957879\n",
      "0.080476254\n",
      "0.112023115\n",
      "0.048846394\n",
      "0.0366697\n",
      "0.06324044\n",
      "0.08750498\n",
      "0.059118718\n",
      "0.06379661\n",
      "0.058598787\n",
      "0.03507614\n",
      "0.059903234\n",
      "0.08348724\n",
      "0.103180826\n",
      "0.06210974\n",
      "0.05388376\n",
      "0.049553156\n",
      "0.032538056\n",
      "0.026578426\n",
      "0.024159878\n",
      "0.037037164\n",
      "0.036628038\n",
      "0.036034137\n",
      "0.03821063\n",
      "0.03552991\n",
      "0.018981189\n",
      "0.011656016\n",
      "0.011275977\n",
      "0.015335679\n",
      "0.024018466\n",
      "0.03319922\n",
      "0.04161954\n",
      "0.033247113\n",
      "0.022968024\n",
      "0.026907176\n",
      "0.03935814\n",
      "0.02610007\n",
      "0.014228255\n",
      "0.010279626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 17:14:16.063115: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-08 17:14:16.085940: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-08 17:14:18.664140: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription (8.254s / audio_len(106477)):  Hello everyone and welcome back to my channel. Today we are going to talk about how we can use blah blah blah for blah blah blah in the blah blah blah.\n",
      "0.010469615\n",
      "0.008298993\n",
      "0.007018566\n",
      "0.006121218\n",
      "0.0035159886\n",
      "0.0039303005\n",
      "0.003566295\n",
      "0.002532959\n",
      "0.0022655725\n",
      "0.0028819442\n",
      "0.0032390654\n",
      "0.04323587\n",
      "0.06375724\n",
      "0.05258605\n",
      "0.03024596\n",
      "0.02040118\n",
      "0.022981882\n",
      "0.0472323\n",
      "0.07997754\n",
      "0.091682285\n",
      "0.08007887\n",
      "0.05085808\n",
      "0.04566881\n",
      "0.07547021\n",
      "0.095885545\n",
      "0.10231084\n",
      "0.089874\n",
      "0.029761195\n",
      "0.041471213\n",
      "0.07279208\n",
      "0.08417165\n",
      "0.12116334\n",
      "0.101495\n",
      "0.063239634\n",
      "0.073292196\n",
      "0.045088857\n",
      "0.034614384\n",
      "0.016103059\n",
      "0.023236066\n",
      "0.0109297335\n",
      "0.014644891\n",
      "0.008585602\n",
      "0.010432273\n",
      "0.005670756\n",
      "0.0060833097\n",
      "0.0045537353\n",
      "0.0038855672\n",
      "0.0036033094\n",
      "0.019996166\n",
      "0.023992121\n",
      "0.026272535\n",
      "0.03474301\n",
      "0.033054143\n",
      "0.035141855\n",
      "0.03932509\n",
      "0.030156404\n",
      "0.009057641\n",
      "0.017849147\n",
      "0.010588288\n",
      "0.02771023\n",
      "0.020217419\n",
      "0.013631165\n",
      "0.0054695904\n",
      "0.0055033267\n",
      "0.0085555315\n",
      "0.010076284\n",
      "0.050402254\n",
      "0.027581483\n",
      "0.031337738\n",
      "0.026233941\n",
      "0.020970881\n",
      "0.015232533\n",
      "0.009556502\n",
      "0.005991161\n",
      "0.0064540207\n",
      "0.0055662394\n",
      "0.0032029748\n",
      "0.0026162565\n",
      "0.0026188493\n",
      "0.002414614\n",
      "0.0018786192\n",
      "0.0023361146\n",
      "0.0018090308\n",
      "0.0017675161\n",
      "0.0020076632\n",
      "0.0024274588\n",
      "0.0018844008\n",
      "0.0015338361\n",
      "0.0014949441\n",
      "0.001403153\n",
      "0.0017343462\n",
      "0.002269864\n",
      "0.00207749\n",
      "0.001789093\n",
      "0.0022538304\n",
      "0.0015766025\n",
      "0.0016549528\n",
      "0.0017017424\n",
      "0.0016028583\n",
      "0.0015993714\n",
      "0.0023187995\n",
      "0.0019004643\n",
      "0.0017633438\n",
      "0.0020063221\n",
      "0.0022172034\n",
      "0.0015577674\n",
      "0.0015871227\n",
      "0.001481086\n",
      "0.0017750561\n",
      "0.00187397\n",
      "0.0016084015\n",
      "0.0017927885\n",
      "0.0025034547\n",
      "0.0019539297\n",
      "0.0020090938\n",
      "0.001822263\n",
      "0.0019269586\n",
      "0.0021166801\n",
      "0.0019616485\n",
      "0.0019183457\n",
      "0.001737982\n",
      "0.0017237067\n",
      "0.0016078651\n",
      "0.0018331707\n",
      "0.0023914874\n",
      "0.0020638406\n",
      "0.001703918\n",
      "0.0017112494\n",
      "0.0019530356\n",
      "0.0015218258\n",
      "0.0017778575\n",
      "0.0019507408\n",
      "0.0018236935\n",
      "0.0019988716\n",
      "0.0018389821\n",
      "0.0023620725\n",
      "0.0018157363\n",
      "0.0019927323\n",
      "0.002742499\n",
      "0.00271672\n",
      "0.0016872287\n",
      "0.0019050539\n",
      "0.0019545257\n",
      "0.0018423796\n",
      "0.002593577\n",
      "0.0021553934\n",
      "0.0019887984\n",
      "0.0024429262\n",
      "0.0018316507\n",
      "0.0028817356\n",
      "0.0022439659\n",
      "0.002008289\n",
      "0.0018822551\n",
      "0.0026179552\n",
      "0.0027180016\n",
      "0.0023765266\n",
      "0.0022461712\n",
      "0.00268054\n",
      "0.0024529994\n",
      "0.0023031235\n",
      "0.0037878156\n",
      "0.0025761127\n",
      "0.0031088293\n",
      "0.0039918423\n",
      "0.0033825636\n",
      "0.0031362176\n",
      "0.0029209554\n",
      "0.0027200878\n",
      "0.0038139224\n",
      "0.0031076372\n",
      "0.003053099\n",
      "0.0028303266\n",
      "0.0030171871\n",
      "0.0035399497\n",
      "0.003740549\n",
      "0.0034666657\n",
      "0.00333485\n",
      "0.0024999678\n",
      "0.002642572\n",
      "0.003388524\n",
      "0.0029746294\n",
      "0.0036214292\n",
      "0.0033957064\n",
      "0.0036470294\n",
      "0.0031897724\n",
      "0.0027006567\n",
      "0.0030009747\n",
      "0.003119409\n",
      "0.0035426617\n",
      "0.0033053458\n",
      "0.003284961\n",
      "0.0024731457\n",
      "0.002895683\n",
      "0.0022717416\n",
      "0.0019584596\n",
      "0.0025470555\n",
      "0.0028207004\n",
      "0.002270341\n",
      "0.0026709735\n",
      "0.003217429\n",
      "0.0036457777\n",
      "0.0031574965\n",
      "0.0028870702\n",
      "0.0023351908\n",
      "0.0028481781\n",
      "0.002936393\n",
      "0.002684474\n",
      "0.0032242537\n",
      "0.0031553507\n",
      "0.0028908849\n",
      "0.0028364658\n",
      "0.0028541088\n",
      "0.0032679439\n",
      "0.0029709935\n",
      "0.003223747\n",
      "0.003073275\n",
      "0.0031109154\n",
      "0.0034328997\n",
      "0.002610445\n",
      "0.0033849776\n",
      "0.0028096437\n",
      "0.0022696257\n",
      "0.0033996701\n",
      "0.0028378665\n",
      "0.003990233\n",
      "0.0027466416\n",
      "0.0032141209\n",
      "0.0040803254\n",
      "0.0034769177\n",
      "0.002791822\n",
      "0.0029356182\n",
      "0.003055334\n",
      "0.0036768913\n",
      "0.003751427\n",
      "0.0045440495\n",
      "0.0032281876\n",
      "0.0038630664\n",
      "0.0034838617\n",
      "0.003156811\n",
      "0.00332731\n",
      "0.0031332672\n",
      "0.0037536323\n",
      "0.0035334826\n",
      "0.0029816628\n",
      "0.0031904578\n",
      "0.0029790103\n",
      "0.0040157735\n",
      "0.0024506152\n",
      "0.0028830767\n",
      "0.002777189\n",
      "0.002821684\n",
      "0.0034874678\n",
      "0.004324287\n",
      "0.0031388104\n",
      "0.003210485\n",
      "0.0024693906\n",
      "0.0031421185\n",
      "0.0031303465\n",
      "0.024810165\n",
      "0.0064596236\n",
      "0.0041388273\n",
      "0.0039084256\n",
      "0.0029754639\n",
      "0.0031219125\n",
      "0.017112672\n",
      "0.017104149\n",
      "0.006490439\n",
      "0.003575176\n",
      "0.00336352\n",
      "0.0026795566\n",
      "0.0030777454\n",
      "0.0025238693\n",
      "0.0024757087\n",
      "0.0020707846\n",
      "0.0028990805\n",
      "0.002665311\n",
      "0.0031902492\n",
      "0.0025202632\n",
      "0.0031856894\n",
      "0.0025498867\n",
      "0.0022899806\n",
      "0.0025003552\n",
      "0.0028701425\n",
      "0.002545327\n",
      "0.0017245412\n",
      "0.0028505027\n",
      "0.0024554133\n",
      "0.0019907951\n",
      "0.0026812851\n",
      "0.0020336509\n",
      "0.0018978119\n",
      "0.0021902025\n",
      "0.001870513\n",
      "0.001677841\n",
      "0.0021806061\n",
      "0.0019464195\n",
      "0.0014536977\n",
      "0.0015779436\n",
      "0.0021050572\n",
      "0.0019723773\n",
      "0.0020338893\n",
      "0.0015536547\n",
      "0.0019917786\n",
      "0.002028644\n",
      "0.001980573\n",
      "0.0018875599\n",
      "0.0015611053\n",
      "0.0019055307\n",
      "0.0023083687\n",
      "0.002117604\n",
      "0.0024709105\n",
      "0.0025922358\n",
      "0.0015696585\n",
      "0.0029565096\n",
      "0.0026364326\n",
      "0.002076149\n",
      "0.0019242465\n",
      "0.0017016232\n",
      "0.002282083\n",
      "0.0021309555\n",
      "0.0021489859\n",
      "0.0019631982\n",
      "0.0021629035\n",
      "0.0019391775\n",
      "0.0019899905\n",
      "0.0015676916\n",
      "0.0024888813\n",
      "0.0015833974\n",
      "0.0017247498\n",
      "0.0021826625\n",
      "0.0019604266\n",
      "0.0021720827\n",
      "0.0033475757\n",
      "0.0048782825\n",
      "0.021994293\n",
      "0.06327596\n",
      "0.094419\n",
      "0.13148072\n",
      "0.12202591\n",
      "0.08008969\n",
      "0.07410464\n",
      "0.08915573\n",
      "0.09263\n",
      "0.055229306\n",
      "0.045412242\n",
      "0.04204437\n",
      "0.057694614\n",
      "0.06345576\n",
      "0.060695976\n",
      "0.051620632\n",
      "0.041828424\n",
      "0.043646365\n",
      "0.044463485\n",
      "0.045734882\n",
      "0.04910153\n",
      "0.05003342\n",
      "0.052790135\n",
      "0.06488159\n",
      "0.06139493\n",
      "0.0484474\n",
      "0.033724427\n",
      "0.02387464\n",
      "0.021565318\n",
      "0.018827826\n",
      "0.014437795\n",
      "0.010826796\n",
      "0.009843081\n",
      "0.0086174905\n",
      "0.007024497\n",
      "0.007107705\n",
      "0.0067866743\n",
      "0.0066129863\n",
      "0.005060166\n",
      "0.0055606663\n",
      "0.003616631\n",
      "0.004503399\n",
      "0.0035014153\n",
      "0.0031466186\n",
      "0.0015155077\n",
      "0.0016987026\n",
      "0.002660662\n",
      "0.001785934\n",
      "0.0021556616\n",
      "0.0022825897\n",
      "0.0025828779\n",
      "0.0027457476\n",
      "0.003524661\n",
      "0.0036886036\n",
      "0.0050637424\n",
      "0.004102677\n",
      "0.0033799112\n",
      "0.0029126704\n",
      "0.0032310486\n",
      "0.0026397407\n",
      "0.0030865073\n",
      "0.0031811\n",
      "0.0034804046\n",
      "0.003907174\n",
      "0.0034672022\n",
      "0.002920568\n",
      "0.0033397377\n",
      "0.0025595129\n",
      "0.0025256872\n",
      "0.00316298\n",
      "0.003282994\n",
      "0.0021716356\n",
      "0.0029301047\n",
      "0.0026631355\n",
      "0.003291607\n",
      "0.0034802258\n",
      "0.0034326315\n",
      "0.0019427538\n",
      "0.0019248128\n",
      "0.0018258691\n",
      "0.0017003417\n",
      "0.0018072426\n",
      "0.0018929839\n",
      "0.0015233457\n",
      "0.0024332702\n",
      "0.012443304\n",
      "0.02319011\n",
      "0.0254229\n",
      "0.031229645\n",
      "0.01778233\n",
      "0.01584354\n",
      "0.016469955\n",
      "0.027136356\n",
      "0.03057462\n",
      "0.028067589\n",
      "0.011746019\n",
      "0.010062039\n",
      "Transcription (1.530s / audio_len(36729)):  But you do not ever require a low end.\n",
      "0.008270144\n",
      "0.009400457\n",
      "0.009623468\n",
      "0.038906872\n",
      "0.028100371\n",
      "0.03757021\n",
      "0.035495937\n",
      "0.032270253\n",
      "0.040596187\n",
      "0.069182575\n",
      "0.085963756\n",
      "0.066595614\n",
      "0.059911728\n",
      "0.054458797\n",
      "0.070565075\n",
      "0.07701409\n",
      "0.060654372\n",
      "0.04629755\n",
      "0.056167483\n",
      "0.021643251\n",
      "0.011434257\n",
      "0.045566857\n",
      "0.049736112\n",
      "0.055671543\n",
      "0.058779955\n",
      "0.06390065\n",
      "0.077922314\n",
      "0.046768785\n",
      "0.06662536\n",
      "0.051962137\n",
      "0.08254728\n",
      "0.05686441\n",
      "0.02538544\n",
      "0.02966243\n",
      "0.019910097\n",
      "0.009620011\n",
      "0.024452418\n",
      "0.050098747\n",
      "0.057904452\n",
      "0.07553923\n",
      "0.08083886\n",
      "0.08248073\n",
      "0.08114177\n",
      "0.081594855\n",
      "0.08069414\n",
      "0.06782961\n",
      "0.06952143\n",
      "0.06960234\n",
      "0.07212013\n",
      "0.03722447\n",
      "0.034347624\n",
      "0.03238094\n",
      "0.036746383\n",
      "0.03932661\n",
      "0.053572387\n",
      "0.024753124\n",
      "0.019160181\n",
      "0.013705879\n",
      "0.01669988\n",
      "0.036513448\n",
      "0.027787715\n",
      "0.03445956\n",
      "0.025348067\n",
      "0.018358558\n",
      "0.025234938\n",
      "0.019625992\n",
      "0.016055882\n",
      "0.01499173\n",
      "0.011698008\n",
      "0.025120944\n",
      "0.025142401\n",
      "0.037197977\n",
      "0.02135545\n",
      "0.012819946\n",
      "0.0071287155\n",
      "0.0050423145\n",
      "0.0036816\n",
      "0.004016608\n",
      "0.003346622\n",
      "0.0027637482\n",
      "0.0024966598\n",
      "0.0027326941\n",
      "0.0019066036\n",
      "0.0019828677\n",
      "0.0026215315\n",
      "0.003322959\n",
      "0.002023846\n",
      "0.0021642447\n",
      "0.0022398233\n",
      "0.0019530058\n",
      "0.0017588139\n",
      "0.0016057491\n",
      "0.0019106865\n",
      "0.0018666685\n",
      "0.0023021698\n",
      "0.0017410815\n",
      "0.0022254288\n",
      "0.0022782683\n",
      "0.0017056465\n",
      "0.0016984344\n",
      "0.0020159185\n",
      "0.0018670261\n",
      "0.0013894439\n",
      "0.0016231835\n",
      "0.0019302368\n",
      "0.0017463863\n",
      "0.0025509\n",
      "0.0018339753\n",
      "0.0028565228\n",
      "0.021946073\n",
      "0.022595584\n",
      "0.02552116\n",
      "0.01515767\n",
      "0.023001373\n",
      "0.02756223\n",
      "0.02753675\n",
      "0.03219691\n",
      "0.029041827\n",
      "0.029340655\n",
      "0.030457735\n",
      "0.028403044\n",
      "0.0121870935\n",
      "0.013819635\n",
      "0.008594215\n",
      "0.005294174\n",
      "0.0072752535\n",
      "0.027575225\n",
      "0.022370428\n",
      "0.024935067\n",
      "0.02124831\n",
      "0.027445257\n",
      "0.049895376\n",
      "0.06145698\n",
      "0.036608458\n",
      "0.020436287\n",
      "0.008848041\n",
      "0.018332541\n",
      "0.02569753\n",
      "0.03143382\n",
      "0.04721695\n",
      "0.03747338\n",
      "0.030446589\n",
      "0.056864083\n",
      "0.061027795\n",
      "0.04144928\n",
      "0.029114068\n",
      "0.020546764\n",
      "0.018534005\n",
      "0.029452026\n",
      "0.050287753\n",
      "0.050255895\n",
      "0.07009202\n",
      "0.07323071\n",
      "0.062215775\n",
      "0.043931186\n",
      "0.01784125\n",
      "0.012879819\n",
      "0.02684626\n",
      "0.044659615\n",
      "0.042479783\n",
      "0.02305299\n",
      "0.01851514\n",
      "0.01700008\n",
      "0.023267299\n",
      "0.014424652\n",
      "0.019811243\n",
      "0.012354076\n",
      "0.009878665\n",
      "0.006374061\n",
      "0.0065987706\n",
      "0.0049985647\n",
      "0.0048241615\n",
      "0.00262627\n",
      "0.0032318532\n",
      "0.003194183\n",
      "0.002816856\n",
      "0.002554834\n",
      "0.0026408732\n",
      "0.0029516518\n",
      "0.0021315217\n",
      "0.001794368\n",
      "0.0018160045\n",
      "0.0018617511\n",
      "0.0021974444\n",
      "0.0030376315\n",
      "0.002769053\n",
      "0.0026869774\n",
      "0.0025382936\n",
      "0.0018271208\n",
      "0.0028239489\n",
      "0.0020767152\n",
      "0.0016217232\n",
      "0.0020180345\n",
      "0.0016039908\n",
      "0.0019280314\n",
      "0.0026299655\n",
      "0.0020157099\n",
      "0.0017675757\n",
      "0.0024597347\n",
      "0.0025310814\n",
      "0.0020622015\n",
      "0.002747625\n",
      "0.001588881\n",
      "0.0021998584\n",
      "0.002363801\n",
      "0.0038621128\n",
      "0.003075093\n",
      "0.0015790462\n",
      "0.0021973848\n",
      "0.0016295016\n",
      "0.001995623\n",
      "0.002243489\n",
      "0.0020719767\n",
      "0.0017205179\n",
      "0.0017834008\n",
      "0.0021525323\n",
      "0.0020414293\n",
      "0.0021067858\n",
      "0.0019227564\n",
      "0.0026858747\n",
      "0.0025961995\n",
      "0.0023060143\n",
      "0.0019251406\n",
      "0.0027036965\n",
      "0.002494514\n",
      "0.002744794\n",
      "0.0024878979\n",
      "0.0021609068\n",
      "0.002867967\n",
      "0.0030763745\n",
      "0.0025470555\n",
      "0.0026768744\n",
      "0.0027977526\n",
      "0.0033211708\n",
      "0.0029296577\n",
      "0.0024273396\n",
      "0.0028432012\n",
      "0.0027742386\n",
      "0.0023394823\n",
      "0.0025056899\n",
      "0.0035955906\n",
      "0.0027616322\n",
      "0.0025012493\n",
      "0.0031046271\n",
      "0.003305018\n",
      "0.0020650327\n",
      "0.001632154\n",
      "0.0035075545\n",
      "0.0034074187\n",
      "0.0042113066\n",
      "0.002461046\n",
      "0.0026019216\n",
      "0.003304571\n",
      "0.0015445352\n",
      "0.002660185\n",
      "0.0030109584\n",
      "0.0028228164\n",
      "0.0028157532\n",
      "0.0014509559\n",
      "0.0027926862\n",
      "0.0023496747\n",
      "0.0019646883\n",
      "0.0021662414\n",
      "0.002918303\n",
      "0.0028963387\n",
      "0.0030421913\n",
      "0.0030840933\n",
      "0.0024542212\n",
      "0.0019402802\n",
      "0.0037398636\n",
      "0.0019215643\n",
      "0.0027073026\n",
      "0.0019423962\n",
      "0.0031612515\n",
      "0.0036346316\n",
      "0.0029870272\n",
      "0.0024600625\n",
      "0.0031502843\n",
      "0.0031338036\n",
      "0.0039616525\n",
      "0.0030056536\n",
      "0.0031179488\n",
      "0.0030788183\n",
      "0.0022944212\n",
      "0.002565384\n",
      "0.0031995773\n",
      "0.002269864\n",
      "0.00308308\n",
      "0.0032158196\n",
      "0.0039567947\n",
      "0.003706783\n",
      "0.0031341612\n",
      "0.0035247207\n",
      "0.0027825832\n",
      "0.003688693\n",
      "0.0030747652\n",
      "0.0035200417\n",
      "0.002971679\n",
      "0.0030713975\n",
      "0.002795875\n",
      "0.0027360916\n",
      "0.002254188\n",
      "0.002839744\n",
      "0.0031242669\n",
      "0.004599482\n",
      "0.002806902\n",
      "0.0023933053\n",
      "0.002520293\n",
      "0.0033191144\n",
      "0.007657379\n",
      "0.013745338\n",
      "0.013612777\n",
      "0.020641416\n",
      "0.015426576\n",
      "0.017585367\n",
      "0.008678973\n",
      "0.005337745\n",
      "0.0067081153\n",
      "0.0055339336\n",
      "0.0042538047\n",
      "0.0029299557\n",
      "0.0033884048\n",
      "0.0031619072\n",
      "0.0027514398\n",
      "0.0023885965\n",
      "0.002584368\n",
      "0.00258407\n",
      "0.0028050244\n",
      "0.0029291809\n",
      "0.0029954016\n",
      "0.0022852123\n",
      "0.0026702285\n",
      "0.0028354526\n",
      "0.0024840534\n",
      "0.0020661056\n",
      "0.0022446513\n",
      "0.0024517775\n",
      "0.0023562312\n",
      "0.0023258328\n",
      "0.0021543205\n",
      "0.0029836595\n",
      "0.0015904903\n",
      "0.002659291\n",
      "0.002154857\n",
      "0.0027149618\n",
      "0.0029402077\n",
      "0.0026564002\n",
      "0.0026659071\n",
      "0.0032836795\n",
      "0.0015757382\n",
      "0.00229308\n",
      "0.001657337\n",
      "0.0022814572\n",
      "0.0023429692\n",
      "0.0021895468\n",
      "0.0017015636\n",
      "0.0018598437\n",
      "0.0020792484\n",
      "0.0022310019\n",
      "0.0028098226\n",
      "0.0021028817\n",
      "0.0026079118\n",
      "0.0019708276\n",
      "0.0018003583\n",
      "0.0014742911\n",
      "0.0016854405\n",
      "0.0020313263\n",
      "0.0015376806\n",
      "0.0016699731\n",
      "0.0021200776\n",
      "0.0017913878\n",
      "0.0014454126\n",
      "0.0020783842\n",
      "0.0019351542\n",
      "0.0019080639\n",
      "0.0015265644\n",
      "0.0019115806\n",
      "0.001288861\n",
      "0.0016986132\n",
      "0.001707077\n",
      "0.001763016\n",
      "0.0018680096\n",
      "0.0015557706\n",
      "0.001663208\n",
      "0.0015656054\n",
      "0.0014218688\n",
      "0.0015354156\n",
      "0.001858741\n",
      "0.0015878379\n",
      "0.0017717779\n",
      "0.001771599\n",
      "0.0013774037\n",
      "0.0015306175\n",
      "0.0016369224\n",
      "0.0017732978\n",
      "0.0018532276\n",
      "0.001627624\n",
      "0.0014791787\n",
      "0.0015435815\n",
      "0.0021292567\n",
      "0.001775533\n",
      "0.0017896295\n",
      "0.0020365417\n",
      "0.0014462769\n",
      "0.0016286969\n",
      "0.0018404126\n",
      "0.0021025836\n",
      "0.0023595989\n",
      "0.0017228723\n",
      "0.0015271008\n",
      "0.0018493533\n",
      "0.0017548203\n",
      "0.0015584826\n",
      "0.001832515\n",
      "0.0020556152\n",
      "0.0018716156\n",
      "0.0014298558\n",
      "0.0013892055\n",
      "0.0017258525\n",
      "0.0019327104\n",
      "0.0015411079\n",
      "0.0017201006\n",
      "0.023722738\n",
      "0.0060201883\n",
      "0.0034720302\n",
      "0.0023949444\n",
      "0.0022221506\n",
      "Stopped listening.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "MIXED_PRECISION = True\n",
    "INPUT_DEVICE = {1:'pc_micro_phone', 2:'pc_speaker', 3:'bluetooth_speaker', 4:'bluetooth_microphone'}\n",
    "\"\"\" for pc_speaker, go to the sound icon and right click-> choose sounds -> recordings -> choose streo Mix as default  \"\"\"\n",
    "INPUT_DEVICE_IDX = 2\n",
    "\n",
    "\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# Optimize PyTorch for CPU\n",
    "# torch.set_num_threads(6)  # Adjust to the number of CPU cores available\n",
    "# Load model and processor\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\").to(device)\n",
    "\n",
    "for params in model.parameters():\n",
    "    params.requires_grad = False\n",
    "    \n",
    "model.eval()\n",
    "\n",
    "# forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"french\", task=\"transcribe\")#for french to french\n",
    "forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"french\", task=\"translate\")#for french to english\n",
    "# forced_decoder_ids = None # for english to english\n",
    "\n",
    "\n",
    "\n",
    "# Initialize PyAudio\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "\n",
    "default_speakers =  p.get_default_input_device_info()\n",
    "\n",
    "\n",
    "print(f'The loopback device is {default_speakers}')\n",
    "\n",
    "# Settings for recording audio\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = int(default_speakers['defaultSampleRate'] ) \n",
    "WISPER_RATE = 16000# Whisper expects 16kHz input\n",
    "CHUNK = 1024  # Number of frames per buffer\n",
    "TRANSCRIPTION_INTERVAL = 10  # Interval for transcription in seconds\n",
    "\n",
    "# Open a stream to record audio\n",
    "\n",
    "stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK, input_device_index=default_speakers[\"index\"])\n",
    "\n",
    "print(\"Listening for audio... Speak now.\")\n",
    "\n",
    "audio_buffer = np.array([], dtype=np.float32)  # Buffer to store accumulated audio\n",
    "last_transcription_time = time.time()  # Initialize the last transcription time\n",
    "audio_frames = []  # Store raw audio frames\n",
    "\n",
    "# Open a text file to save the transcriptions\n",
    "transcription_file = open(\"transcriptions_cpu.txt\", \"a\")\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "\n",
    "        # Read a chunk of audio\n",
    "        data = stream.read(CHUNK, exception_on_overflow=False)  # Read a chunk of audio (1024 samples per chunk\n",
    "        audio_frames.append(data)  # Save raw audio data for MP3 conversion\n",
    "        audio_chunk = np.frombuffer(data, np.int16).flatten().astype(np.float32) / 32768.0\n",
    "        downsampled_chunk = resample(audio_chunk, int(len(audio_chunk) * WISPER_RATE / RATE))  # Resample to 16kHz\n",
    "\n",
    "        \n",
    "        if np.abs(audio_chunk).mean() > 0.01:\n",
    "            audio_buffer = np.append(audio_buffer, downsampled_chunk)\n",
    "            \n",
    "        print(np.abs(audio_chunk).mean())\n",
    "\n",
    "        # Check if it's time to perform transcription\n",
    "        current_time = time.time()\n",
    "        if current_time - last_transcription_time >= TRANSCRIPTION_INTERVAL:\n",
    "            if audio_buffer.size > 0:  # Ensure there's audio to transcribe\n",
    "\n",
    "                start_translation_time = time.time()\n",
    "\n",
    "                input_features = processor(audio_buffer, sampling_rate=WISPER_RATE, return_tensors=\"pt\").input_features\n",
    "                # Generate token ids\n",
    "                with torch.no_grad():\n",
    "                    predicted_ids = model.generate(input_features.to(device), forced_decoder_ids=forced_decoder_ids)\n",
    "                # Decode token ids to text\n",
    "                transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
    "                transcription_text = transcription[0]\n",
    "\n",
    "                translation_duration = time.time() - start_translation_time\n",
    "\n",
    "                # Save the transcription with a timestamp to the file\n",
    "                timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                transcription_file.write(f\"[{timestamp}] {transcription_text}\\n\")\n",
    "                transcription_file.flush()  # Ensure it's written to the file immediately\n",
    "\n",
    "\n",
    "                # Print the transcription\n",
    "                print(f\"Transcription ({translation_duration:0.3f}s / audio_len({audio_buffer.size})): {transcription_text}\")\n",
    "\n",
    "                # Clear buffer after transcription\n",
    "                audio_buffer = np.array([], dtype=np.float32)\n",
    "\n",
    "            last_transcription_time = current_time  # Update last transcription time\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Stopped listening.\")\n",
    "        # save_wave(audio_frames, idx=1)\n",
    "        break\n",
    "\n",
    "# Stop and close the stream\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'index': 0, 'structVersion': 2, 'name': 'sof-hda-dsp: - (hw:0,7)', 'hostApi': 0, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.016, 'defaultLowOutputLatency': -1.0, 'defaultHighInputLatency': 0.096, 'defaultHighOutputLatency': -1.0, 'defaultSampleRate': 16000.0}\n",
      "{'index': 1, 'structVersion': 2, 'name': 'pulse', 'hostApi': 0, 'maxInputChannels': 32, 'maxOutputChannels': 32, 'defaultLowInputLatency': 0.008684807256235827, 'defaultLowOutputLatency': 0.008684807256235827, 'defaultHighInputLatency': 0.034807256235827665, 'defaultHighOutputLatency': 0.034807256235827665, 'defaultSampleRate': 44100.0}\n",
      "{'index': 2, 'structVersion': 2, 'name': 'default', 'hostApi': 0, 'maxInputChannels': 32, 'maxOutputChannels': 32, 'defaultLowInputLatency': 0.008684807256235827, 'defaultLowOutputLatency': 0.008684807256235827, 'defaultHighInputLatency': 0.034807256235827665, 'defaultHighOutputLatency': 0.034807256235827665, 'defaultSampleRate': 44100.0}\n"
     ]
    }
   ],
   "source": [
    "import pyaudio # import pyaudiowpatch as pyaudio (windows)\n",
    "p = pyaudio.PyAudio()\n",
    "for i in range(p.get_device_count()):\n",
    "    print(p.get_device_info_by_index(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello everyone and welcome back to my channel. Today we are going to talk about\n",
      " Hiking Face and how we can use it for multitude of things.\n",
      " In this video we have multiple things such as aloo, matter I'm going to do it again. Hello everyone and welcome to a new video on Learn to French.\n",
      " My name is Eden and I teach French.\n",
      " to another video on learn to French. If you are new here, my name is Eden and I teach French. Today we will work on your oral comprehension. This video is for the learners of level B1.\n",
      " So this video is for B1 learners. However, if you are A2 or even A1, you can always participate.\n",
      " It's still great content for you to practice your listening comprehension skills.\n",
      " So, how are we going to get this video?\n",
      " First, you're going to listen to the texts.\n",
      " So first, you're going to listen to the texts.\n",
      " I will be reading them for you.\n",
      " Then, you're going to answer a few questions. Then, you're Then you will answer a few questions.\n",
      " Then you are going to answer a few comprehension questions.\n",
      " At the end of each text, you will also have the written version and the answer to these questions.\n",
      " So before I start this video, I also wanted to take a brief moment to thank today's partner,\n",
      " which he has learned to French myself.\n",
      " But we are going to talk about it a bit later in this video.\n",
      " Make sure to deactivate the subtitles feature because the subtitles that you need are going\n",
      " to be in the video directly.\n",
      " So there's no need to change any settings.\n",
      " The subtitles that you need will be in the video.\n",
      " Est-ce que vous êtes prêts? any settings, the subtitles that you need will be in the video. Are you ready?\n",
      " First text.\n",
      " Life in town.\n",
      " Life in town has a lot of advantages.\n",
      " You can easily find work and there is always something to do.\n",
      " Common transport is practical and you don't need a car.\n",
      " On the other hand, pollution and noise can be tiring.\n",
      " The rents are often expensive and housing small.\n",
      " Despite these disadvantages, many people prefer to live in cities\n",
      " to enjoy diversity and dynamism.\n",
      " Great, here is the first question for the first text. What are the two advantages of city life mentioned in the text?\n",
      " Second question, what are the disadvantages linked to housing in the city?\n",
      " Third question, why do people choose to live in the city despite the inconveniences.\n",
      " Now you will look at the version with the subtitles.\n",
      " The life in the city. The life in the city has a lot of advantages. You can easily find work and there is always something to do.\n",
      " Common transport is practical and you don't need a car.\n",
      " On the other hand, pollution and noise can be tiring.\n",
      " The rents are often expensive and the housing is small.\n",
      " Despite these inconveniences, many people prefer to live in cities to from diversity and dynamism.\n",
      " Very well, we will answer the questions.\n",
      " First question.\n",
      " What are the two advantages of life in cities mentioned in the text?\n",
      " Well, the two advantages are that you can easily find work\n",
      " and there is always something to do.\n",
      " Second question.\n",
      " What are the disadvantages related to housing in the city? Simply, the rents are often\n",
      " expensive and housing small. Third question, why do people choose to live in\n",
      " city despite the inconveniences? Many people prefer to live in the city to\n",
      " enjoy diversity and dynamism.\n",
      " Let's move on to the text number 2.\n",
      " summer holidays\n",
      " Last summer, I spent two weeks in Brittany with my family.\n",
      " We rented a small house near the beach.\n"
     ]
    }
   ],
   "source": [
    "# pip install PyAudioWPatch\n",
    "\n",
    "# import time\n",
    "# from transformers import  pipeline\n",
    "# import torch\n",
    "\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "# pipe  = pipeline(\"automatic-speech-recognition\",\n",
    "#                     \"openai/whisper-small\", \n",
    "#                     chunk_length_s=30,\n",
    "#                     stride_length_s=5,\n",
    "#                     return_timestamps=True,\n",
    "#                     device=device, \n",
    "#                     generate_kwargs = {\"language\": 'fr', \"task\": \"translate\"}) # if you don't have GPU, r\n",
    "\n",
    "for params in pipe.model.parameters():\n",
    "    params.requires_grad = False\n",
    "    \n",
    "pipe.model.eval()\n",
    "with torch.no_grad():\n",
    "    transcription = pipe(\"temp_audio_1.wav\" )\n",
    "\n",
    "\n",
    "\n",
    "formatted_lyrics = \"\"\n",
    "for line in transcription['chunks']:\n",
    "    text = line[\"text\"]\n",
    "    formatted_lyrics += f\"{text}\\n\"\n",
    "\n",
    "print(formatted_lyrics.strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
